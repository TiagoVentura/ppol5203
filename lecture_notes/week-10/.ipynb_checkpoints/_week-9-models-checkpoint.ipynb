{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e380a95",
   "metadata": {},
   "source": [
    "<h1><center> PPOL 5203 Data Science I: Foundations <br><br> \n",
    "<font color='grey'> Inferential Models and Machine Learning in Python<br><br>\n",
    "Tiago Ventura </center> <h1> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4eed89",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "\n",
    "In the class today, we will learn about model in Python. We will cover:\n",
    "\n",
    "- Inferential models using `statsmodels`\n",
    "    - Ordinary Least Squares\n",
    "    - Logistic Regression\n",
    "    - Retrieving parameters of interest\n",
    "   \n",
    "- Statistical learning with `sklearn`\n",
    "    - an workflow to rule them all\n",
    "    - iterating through many models\n",
    "    - model selection\n",
    "    - cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4ae231",
   "metadata": {},
   "source": [
    "## Introdutory notes\n",
    "\n",
    "In Data Science II, you will learn all there is to be learned about predictive modeling and machine learning. You will spend every week going through a different type of model and understanding the mathematics behind it. \n",
    "\n",
    "The purpose of this class is to provide you with a agnostic overview of inferential and predictive workflow of building models in Python. These are my broader goals on having this class in DS I: \n",
    "\n",
    "- For inferential models, my goal is to show you how to use Python to estimate the models you are learning at Statistics I. \n",
    "\n",
    "- For the predictive modeling, I want to go give you a foundational introduction to Machine Learning. In case you get an interview for an internship before you start Data Science II, this class should make you feel confortable describing the components of a machine learning pipeline, even though you have not been properly introduced properly to each different model. \n",
    "\n",
    "- The predictive modeling components will also help you understand the next two lecture of this course focusing on modeling text data in Python. \n",
    "\n",
    "Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915f5277",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "We will work with the Diabetes dataset provided by the `sklearn` library. [Here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes) you can find a full description of the dataset. \n",
    "\n",
    "Some basic information: \n",
    "\n",
    "- Number of cases: 442\n",
    "\n",
    "- Number of variables: First 10 columns are numeric predictive values\n",
    "\n",
    "- Outcome (Target in ML): Column 11 is a quantitative measure of disease progression one year after baseline\n",
    "\n",
    "- Attribute Information:\n",
    "\n",
    "    - `age:` age in years\n",
    "\n",
    "    - `sex:` gender assigned at birth\n",
    "\n",
    "    - `bmi:` body mass index\n",
    "\n",
    "    - `bp:` average blood pressure\n",
    "\n",
    "    - `s1 tc:`, total serum cholesterol\n",
    "\n",
    "    - `s2 ldl:`, low-density lipoproteins\n",
    "\n",
    "    - `s3 hdl:`, high-density lipoproteins\n",
    "\n",
    "    - `s4 tch:`, total cholesterol / HDL\n",
    "\n",
    "    - `s5 ltg:`, possibly log of serum triglycerides level\n",
    "\n",
    "    - `s6 glu:`, blood sugar level\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a9fb9f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "# load the dataset as a pandas dataframe\n",
    "diabetes = datasets.load_diabetes(as_frame=True)[\"frame\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac88cc0c",
   "metadata": {},
   "source": [
    "#### Notice: \n",
    "\n",
    "- ten features (independent variables)\n",
    "- one outcome (target variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "05c7edb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  target  \n",
       "0 -0.002592  0.019907 -0.017646   151.0  \n",
       "1 -0.039493 -0.068332 -0.092204    75.0  \n",
       "2 -0.002592  0.002861 -0.025930   141.0  \n",
       "3  0.034309  0.022688 -0.009362   206.0  \n",
       "4 -0.002592 -0.031988 -0.046641   135.0  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8032984c",
   "metadata": {},
   "source": [
    "## Inferential Models\n",
    "\n",
    "As we discussed in class, the goal of inferential models is **_interpretation_**. These are the models we often build when doing statistics in social science. We often ask: \n",
    "  \n",
    "- _Which predictors are associated with the response?_\n",
    "- _What is the relationship (parameters) between the response and the predictors?_\n",
    "- _Is the relationship causal?_\n",
    "\n",
    "To work with inference, we will use the library `statsmodels` which will allow us to estimate and easily retrive parameters for a wide set of models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cbd933c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library for models\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# library for plotting\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6175f97a",
   "metadata": {},
   "source": [
    "#### Fitting a OLS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "11b9fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the model using R style formula\n",
    "# notice the .fit methods at the end. \n",
    "model_ols_r = smf.ols(formula='target ~ age + sex + bmi + bp', data=diabetes).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c75a7fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or using a more pythonic way\n",
    "X = sm.add_constant(diabetes[[\"age\", \"sex\", \"bmi\", \"bp\"]])\n",
    "y = diabetes[[\"target\"]]\n",
    "model_ols = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7eeaffbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x30fbc93d0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0072ae7f",
   "metadata": {},
   "source": [
    "#### See outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "efe98424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   R-squared:                       0.400\n",
      "Model:                            OLS   Adj. R-squared:                  0.395\n",
      "Method:                 Least Squares   F-statistic:                     72.91\n",
      "Date:                Mon, 03 Nov 2025   Prob (F-statistic):           2.70e-47\n",
      "Time:                        20:45:31   Log-Likelihood:                -2434.2\n",
      "No. Observations:                 442   AIC:                             4878.\n",
      "Df Residuals:                     437   BIC:                             4899.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        152.1335      2.853     53.329      0.000     146.527     157.740\n",
      "age           37.2406     64.117      0.581      0.562     -88.776     163.258\n",
      "sex         -106.5762     62.125     -1.716      0.087    -228.677      15.525\n",
      "bmi          787.1817     65.424     12.032      0.000     658.597     915.766\n",
      "bp           416.6725     69.495      5.996      0.000     280.087     553.258\n",
      "==============================================================================\n",
      "Omnibus:                        9.858   Durbin-Watson:                   1.933\n",
      "Prob(Omnibus):                  0.007   Jarque-Bera (JB):                6.464\n",
      "Skew:                           0.146   Prob(JB):                       0.0395\n",
      "Kurtosis:                       2.485   Cond. No.                         28.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(model_ols.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2a0eb8",
   "metadata": {},
   "source": [
    "#### Fitting OLS models with interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "11df15f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   R-squared:                       0.407\n",
      "Model:                            OLS   Adj. R-squared:                  0.400\n",
      "Method:                 Least Squares   F-statistic:                     59.77\n",
      "Date:                Mon, 03 Nov 2025   Prob (F-statistic):           2.40e-47\n",
      "Time:                        20:45:38   Log-Likelihood:                -2431.8\n",
      "No. Observations:                 442   AIC:                             4876.\n",
      "Df Residuals:                     436   BIC:                             4900.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    150.9570      2.892     52.203      0.000     145.274     156.640\n",
      "age           52.4516     64.228      0.817      0.415     -73.783     178.686\n",
      "sex         -102.7047     61.887     -1.660      0.098    -224.339      18.930\n",
      "bmi          813.1607     66.233     12.277      0.000     682.985     943.336\n",
      "bp           413.1195     69.219      5.968      0.000     277.075     549.164\n",
      "age:bmi     2809.4786   1291.944      2.175      0.030     270.265    5348.692\n",
      "==============================================================================\n",
      "Omnibus:                        8.252   Durbin-Watson:                   1.934\n",
      "Prob(Omnibus):                  0.016   Jarque-Bera (JB):                6.273\n",
      "Skew:                           0.184   Prob(JB):                       0.0434\n",
      "Kurtosis:                       2.547   Cond. No.                         455.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_ols_int= smf.ols(formula='target ~ age + sex + bmi + bp + age*bmi', data=diabetes).fit()\n",
    "print(model_ols_int.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbb3567",
   "metadata": {},
   "source": [
    "#### Logit models\n",
    "\n",
    "The API for `stats.model` is the same for different types of models. So the learning costs of estimating different models are quite low. Let's estimate a logit model now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "478860f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.536502\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:             target_bin   No. Observations:                  442\n",
      "Model:                          Logit   Df Residuals:                      437\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Mon, 03 Nov 2025   Pseudo R-squ.:                  0.2182\n",
      "Time:                        20:45:49   Log-Likelihood:                -237.13\n",
      "converged:                       True   LL-Null:                       -303.31\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.229e-27\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.2809      0.113     -2.495      0.013      -0.502      -0.060\n",
      "age            1.1068      2.569      0.431      0.667      -3.929       6.142\n",
      "sex           -3.7533      2.459     -1.526      0.127      -8.573       1.066\n",
      "bmi           19.5943      2.852      6.871      0.000      14.005      25.183\n",
      "bp            14.6430      2.875      5.092      0.000       9.007      20.279\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# estimate the model using R style formula\n",
    "diabetes[\"target_bin\"] = np.where(diabetes[\"target\"]> np.mean(diabetes[\"target\"]), 1, 0)\n",
    "\n",
    "# model\n",
    "model_logit = smf.logit(formula='target_bin ~ age + sex + bmi + bp', data=diabetes).fit()\n",
    "\n",
    "# see output\n",
    "print(model_logit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9def05",
   "metadata": {},
   "source": [
    "### Understanding the Model Quantities\n",
    "\n",
    "If we are interested in understanding relationships, a huge part of fitting inferential models consists on presenting the results as understanble quantities of interests. `statsmodels` has a set of functions that allow us to easily analyze the model. \n",
    "\n",
    "#### Retrieving model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a5b0db39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>152.133484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>37.240607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-106.576199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>787.181650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>416.672511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef\n",
       "const  152.133484\n",
       "age     37.240607\n",
       "sex   -106.576199\n",
       "bmi    787.181650\n",
       "bp     416.672511"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get parameters\n",
    "params = model_ols.params\n",
    "pd.DataFrame(params).rename(columns={0:\"coef\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2daecb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>146.526670</td>\n",
       "      <td>157.740298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-88.776333</td>\n",
       "      <td>163.257546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-228.677180</td>\n",
       "      <td>15.524781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>658.596846</td>\n",
       "      <td>915.766454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>280.087493</td>\n",
       "      <td>553.257528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lower       upper\n",
       "const  146.526670  157.740298\n",
       "age    -88.776333  163.257546\n",
       "sex   -228.677180   15.524781\n",
       "bmi    658.596846  915.766454\n",
       "bp     280.087493  553.257528"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confidence intervals\n",
    "model_ols.conf_int().rename(columns={0:\"lower\", 1:\"upper\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bb4542cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>2.048854e-193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>5.616622e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>8.696030e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>5.342370e-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>4.245775e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            p-values\n",
       "const  2.048854e-193\n",
       "age     5.616622e-01\n",
       "sex     8.696030e-02\n",
       "bmi     5.342370e-29\n",
       "bp      4.245775e-09"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p-values\n",
    "pd.DataFrame(model_ols.pvalues).rename(columns={0:\"p-values\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2cf43147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to get a tidy data frame with results\n",
    "def tidy_ols(model):\n",
    "    \"\"\"\n",
    "    input: ols stats model\n",
    "    output: tidy pandas dataframe with models parameters\n",
    "    \n",
    "    \"\"\"\n",
    "    # parameters\n",
    "    params = pd.DataFrame(model.params).rename(columns={0:\"coef\"})\n",
    "    \n",
    "    # confidence intervals\n",
    "    coinf = model.conf_int().rename(columns={0:\"lower\", 1:\"upper\"})\n",
    "    \n",
    "    # p-values\n",
    "    pvalues = pd.DataFrame(model.pvalues).rename(columns={0:\"p-values\"})\n",
    "    \n",
    "    return pd.concat([params, coinf, pvalues], axis=1).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2a1b03dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>coef</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>p-values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>const</td>\n",
       "      <td>152.133484</td>\n",
       "      <td>146.526670</td>\n",
       "      <td>157.740298</td>\n",
       "      <td>2.048854e-193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>37.240607</td>\n",
       "      <td>-88.776333</td>\n",
       "      <td>163.257546</td>\n",
       "      <td>5.616622e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sex</td>\n",
       "      <td>-106.576199</td>\n",
       "      <td>-228.677180</td>\n",
       "      <td>15.524781</td>\n",
       "      <td>8.696030e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bmi</td>\n",
       "      <td>787.181650</td>\n",
       "      <td>658.596846</td>\n",
       "      <td>915.766454</td>\n",
       "      <td>5.342370e-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bp</td>\n",
       "      <td>416.672511</td>\n",
       "      <td>280.087493</td>\n",
       "      <td>553.257528</td>\n",
       "      <td>4.245775e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        coef       lower       upper       p-values\n",
       "0  const  152.133484  146.526670  157.740298  2.048854e-193\n",
       "1    age   37.240607  -88.776333  163.257546   5.616622e-01\n",
       "2    sex -106.576199 -228.677180   15.524781   8.696030e-02\n",
       "3    bmi  787.181650  658.596846  915.766454   5.342370e-29\n",
       "4     bp  416.672511  280.087493  553.257528   4.245775e-09"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the function\n",
    "ols_tidy = tidy_ols(model_ols)\n",
    "\n",
    "# see\n",
    "ols_tidy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e85f61",
   "metadata": {},
   "source": [
    "#### Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1e79adc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABQAAAAPACAYAAABq3NR5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAB7CAAAewgFu0HU+AACCj0lEQVR4nOzdeZxddX0//tckM5M9IStJgICRzQRBkdUiICCyK1+L/am0Yl2Atq51qdYK1IVibV0Kai2K1JaKCgooaIhggEQiiyIkhABRE7Jnsg+ZNff3x80sN3vCZCY583w+Hnkwuee877wv531meeV8zq0qlUqlAAAAAACF1KenGwAAAAAA9hwBIAAAAAAUmAAQAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBgAkAAAAAAKDABIAAAAAAUmAAQAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBgAkAAAAAAKDABIAAAAAAUmAAQAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBgAkAAAAAAKDABIAAAAAAUmAAQAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBgAkAAAAAAKDABIAAAAAAUmAAQAAAAAApMAAgAAAAABVbd0w3QfR588ME0Njb2dBsAAAAAvAT9+vXL6173up3eXwDYizQ2NqahoaGn22Av0bdv3+y3335ZvXp1Wltbe7odKDTnG3Qf5xt0D+cadB/nG11BANhL9e/fv6dboIfV1NRk5MiRaWpqSnNzc0+3A4XmfIPu43yD7uFcg+7jfKOz3b2wSwDYC/Xv3z9nnXVWT7dBD2toaMj8+fNz4oknCoRhD3O+QfdxvkH3cK5B93G+0dnUqVN3KwT0JiAAAAAAUGACQAAAAAAoMAEgAAAAABSYABAAAAAACkwACAAAAAAFJgAEAAAAgAITAAIAAABAgQkAAQAAAKDABIAAAAAAUGACQAAAAAAoMAEgAAAAABSYABAAAAAACkwACAAAAAAFJgAEAAAAgAITAAIAAABAgQkAAQAAAKDABIAAAAAAUGACQAAAAAAoMAEgAAAAABSYABAAAAAACkwACAAAAAAFJgAEAAAAgAITAAIAAABAgQkAAQAAAKDABIAAAAAAUGACQAAAAAAoMAEgAAAAABSYABAAAAAACkwACAAAAAAFJgAEAAAAgAITAALAHjZ16tQ89NBDPd0GAADQSwkAAWAPa2pqSnNzc0+3AQAA9FICQAAAAAAoMAEgAAAAABSYABAAAAAACqy6pxsAgKKZMmVKmpqa2v/+6KOPZs2aNbn77rtTW1ubJKmtrc3ZZ5/dUy0CAAC9iCsAAQAAAKDABIAAAAAAUGACQAAAAAAoMAEgAOxh1dXVqa52210AAKBn+G0EAPawV73qVVm+fHlPtwEAAPRSrgAEAAAAgAITAAIAAABAgQkAAQAAAKDABIAAAAAAUGACQAAAAAAoMAEgAAAAABSYABAAAAAACkwACAAAAAAFJgAEAAAAgAITAAIAAABAgQkAAQAAAKDABIAAAAAAUGACQAAAAAAoMAEgAAAAABSYABAAAAAACkwACAAAAAAFJgAEAAAAgAITAAIAAABAgQkAAQAAAKDABIAAAAAAUGDVPd0A3WvUqFEZM2ZM1q1b19Ot0MM2btyYIUOGpLGxMc3NzT3dDhTKiy++mKampva/l0qlDBgwIM3NzWlpaUmStLS0+FoMe4Dvb9A9nGvQfZxvdDZx4sTMnj17l+sEgL3MihUrsn79+kycOLGnW6GHNTQ0ZOnSpRk+fHj69+/f0+1AoQwcODDV1R3fYpuamrJ69eoMHjw4tbW1SZLa2toMGTKkp1qEwvL9DbqHcw26j/ONzmbOnLlbdZYAAwAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKrLqnGwCAwpo/P5k1K33Wrs2g5uZUTZyYnHhi0rdvT3cGAAD0IgJAAOhKra3JtGnJnXcmTz2VpPzNdr+27SNGJG98Y3LhhT3UIAAA0NsIAAGgq6xbl/z5nydTpmx7n5Urk//7v+SnP00OPDB53eu6rz8AAKBXcg9AAOgKDQ3JueduP/zrbN268pWAv/71nu0LAADo9QSAANAVPvGJZPr0XavZsCF505uS+vo90xMAAEAEgADw0q1dm3znO7tXu3x58r//27X9AAAAdCIABICX6r//O1m/fvfrv/71rusFAABgMwJAAHipXuoVfE88kcya1TW9AAAAbEYACAAv1eLFe8dzAAAAbIUAEABeqpaWl/4czc0v/TkAAAC2QgAIAC/ViBF7x3MAAABshQAQAF6q8857afXjxiXHHts1vQAAAGxGAAgAL9UVVyR9XsK31Pe8J6mp6bp+AAAAOhEAAsBLdcghu38VYHV18r73dWk7AAAAnQkAAaAr/Md/JGPH7nrdV76SHHhgl7cDAADQRgAIAF3hkEOSX/wiGT9+52uuvTb527/dYy0BAAAkAkAA6DpHH53MnJmce27Sr9+293vFK5Jrrkn+4R+6rzcAAKDXqu7pBgCgUA48MPnQh5J3vjP55S+TWbPSWl+fplIptQcdlL5vfGPyspcltbU93SkAANBLCAABYE8YNCi56KLkoovS2tSUlcuXZ/To0ekr+AMAALqZJcAAAAAAUGACQAAAAAAoMAEgAAAAABSYewBux9KlS/Pe9753p/c/6qij8oUvfCFJcv3112fWrFnb3f+DH/xgjjzyyIrHmpqaMmXKlNx3331ZtGhR+vTpk/Hjx+f000/Pueeem759++76CwEAAACg1xIAbkd1dXUOOOCAHe63YsWKNDY2ZujQoe2PzZo1KwsXLtxuXUNDQ8XfGxsbc8011+Spp55KkgwbNix9+vTJ3LlzM3fu3EyfPj1XX311+vXrtxuvBgAAAIDeSAC4HSNHjsw3vvGN7e7z7LPP5hOf+ERGjRqVK664IknS2tqapUuXZvTo0fn2t7+905/vpptuylNPPZVhw4blYx/7WI4++ugkyTPPPJNrr702s2bNyk033dT+eQAAAABgR9wD8CWor6/Pv/7rv2bjxo35+7//++y3335JkuXLl6elpSXjx4/f6edavnx5pkyZkiS58sor28O/JDniiCPalyL/4he/yIoVK7ruRQAAAABQaALAl+Bb3/pWlixZkosuuiiTJ09uf3zx4sVJknHjxu30c82cOTMtLS0ZOXJkTjrppC22H3fccampqUlra2sefvjhl948AAAAAL2CAHA3PfXUU7n//vszatSovO1tb6vYtjsB4O9///skyeTJk9Onz5aHpV+/fjniiCOSlJcEAwAAAMDOcA/A3dDS0tJ+b8B3vetdGTBgQMX2tgAwSb785S/niSeeyNq1azNo0KAcfvjhOf/883PsscdW1CxYsCBJtrtsePTo0UmSJUuWdMnrAAAAAKD4BIC7YerUqVmwYEEOPvjgnHLKKVtsbwsAb7rppiTld/MdMmRIVq1alUceeSSPPPJIzjvvvFx++eWpqqpKkqxbty5J2u8juDVDhgxJUr73IAAAAADsDAHgLmpubs4Pf/jDJMlb3/rW9gCvs7YAcPLkybn88stzyCGHJEnq6uryve99L/fdd1/uvvvujB49Om95y1uSdIR6NTU12/zc/fv3T1K+AhEAAAAAdoYAcBfdf//9Wb58eUaPHp3Xvva1W93n0ksvTWtra0488cSKQG/kyJH50Ic+lNbW1kybNi0/+tGP8qY3vSnV1dXp27dvWltbs3Hjxm1+7ubm5iTl+wECAAAAwM4QAO6ie+65J0lyzjnnpG/fvlvd5+STT97uc7zxjW/MtGnTUl9fnwULFuRlL3tZhgwZkrq6uqxfv36bdW1XCY4YMWKb+8ybNy/z5s3b6raGhoZUVVWlpqYmDQ0N2+2R4mtqaqr4L9B1mpqaKs6ttiu3N7+C29di6Hq+v0H3cK5B93G+0dnuZjoCwF3w7LPP5vnnn09VVVXOOOOM3X6eYcOGtX/cdgKPHz8+dXV1FW8gsrmlS5cmSQ488MBt7tPc3LzdQejfv3/GjRuX+fPn72rbFJQ3lYGut2zZsvartjtbtWpV+8c1NTW+FsMe5PsbdA/nGnQf5xtJMm7cuPb3kdgVAsBd8MADDyRJXvGKV2TkyJFb3WfGjBl57LHHMmHChLzpTW/a6j5t7/ibJPvvv3+S8v0Cn3zyyTz55JNbrWlpacncuXOTJEcdddQ2e6ypqWm/V+DmGhoa0tDQkMWLF+fEE0/c5nPQOzQ1NWXJkiUZO3Zsamtre7odKJQxY8ZscQXgqlWrMnz48FRXl7/11tbWZsKECT3VIhSW72/QPZxr0H2cb3Q2c+bM3aoTAO6Ctv/Jxx9//Db3aWxszL333ptBgwblzDPPzODBg7fY584770ySHHnkke3v+nvKKafk1ltvzeLFi/Poo4/muOOOq6i57777smHDhgwZMmSLbZ1NnDgxEydO3Oq2qVOnpqGhIc3NzdsMCel9amtrzQN0sW39YFZdXd2+zbkHe5ZzDLqHcw26j/ONJFtdabQz+nRxH4X1wgsvtF9uO3ny5G3ud9JJJ2X48OGpr6/PZz/72Yqr/datW5evf/3rmT17dqqqqnLppZe2b5swYUJOPfXUJMnXvva1zJkzJ0lSKpUyY8aM3HjjjUnKbzCyvXcKBgAAAIDOXAG4k5555pkk5SW2L3/5y7e534ABA/KJT3win/vc5/L000/nb//2bzN8+PDU1NRkxYoV2bhxY6qqqvLud787Rx99dEXtlVdemYULF+a5557Lxz/+8YwYMSLNzc3ta7vPPPPMnHPOOXvuRQIAAABQOALAnfTss88mSQ455JAdXoE3adKk3HDDDbnjjjvyyCOPZMmSJamqqsqYMWMyadKkXHDBBTn00EO3qBs4cGCuu+66/OQnP8kDDzyQJUuWpLa2NpMmTcq5556b0047bY+8NgAAAACKSwC4k6644opcccUVO73/8OHDc9lll+Wyyy7bpc9TU1OTSy65JJdccskudggAAAAAW3IPQAAAAAAoMAEgAAAAABSYABAAAAAACkwACAAAAAAFJgAEAAAAgAITAAIAAABAgQkAAQAAAKDABIAAAAAAUGACQAAAAAAoMAEgAAAAABSYABAAAAAACkwACAAAAAAFJgAEAAAAgAITAAIAAABAgQkAAQAAAKDABIAAAAAAUGACQAAAAAAoMAEgAAAAABSYABAAAAAACkwACAAAAAAFJgAEAAAAgAITAAIAAABAgQkAAQAAAKDABIAAAAAAUGACQAAAAAAoMAEgAAAAABSYABAAAAAACkwACAAAAAAFJgAEAAAAgAITAAIAAABAgQkAAQAAAKDABIAAAAAAUGACQAAAAAAoMAEgAAAAABSYABAAAAAACkwACAAAAAAFJgAEAAAAgAITAAIAAABAgQkAAQAAAKDABIAAAAAAUGACQAAAAAAoMAEgAAAAABSYABAAAAAACkwACAAAAAAFJgAEAAAAgAITAAIAAABAgQkAAQAAAKDABIAAAAAAUGACQADYw373u99l9uzZPd0GAADQSwkAAWAPa2lpSUtLS0+3AQAA9FICQAAAAAAoMAEgAAAAABSYABAAAAAACqy6pxsAgKI5++yzK/7e1NSU5cuX57zzzkv//v17qCsAAKC3cgUgAAAAABSYABAAAAAACkwACAAAAAAFJgAEgD2strY2NTU1Pd0GAADQS3kTEADYw84666zMnz+/p9sAAAB6KVcAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAqvu6QboXqNGjcqYMWOybt26nm6FHrZx48YMGTIkjY2NaW5u7ul2oNCcb9B9nG/QPZxr0H2cb3Q2ceLEzJ49e5frBIC9zIoVK7J+/fpMnDixp1uhhzU0NGTp0qUZPnx4+vfv39PtQKE536D7ON+gezjXoPs43+hs5syZu1VnCTAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYNU93QAAAHSFKVOmpKmpKcuWLcvb3/72nm4HAGCv4QpAAAAKoampKU1NTWlubu7pVgAA9ioCQAAAAAAoMAEgAAAAABSYABAAAAAACsybgAAAsM9qe+OPJPnNb36TlpaWrFmzJnfffXdqa2uTJLW1tTn77LN7sk0AgB7lCkAAAAAAKDABIAAAAAAUmAAQAAAAAArMPQABACiE6urqiv8CAFDmpyMAAArh2GOPTVNTU5YvX97TrQAA7FUsAQYAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBVfd0A/uCxx57LDfeeON29znhhBPyrne9q+KxWbNm5fbbb8+8efOybt26jBgxIq95zWvy5je/Ofvvv/9Wn6epqSlTpkzJfffdl0WLFqVPnz4ZP358Tj/99Jx77rnp27dvl70uAAAAAIpPALgT5s2bl4ULF253n5UrV1b8/e677843v/nNJEm/fv2y3377ZcWKFfnZz36WadOm5dOf/nQmTZpUUdPY2JhrrrkmTz31VJJk2LBh6dOnT+bOnZu5c+dm+vTpufrqq9OvX78ufHUAAAAAFJkAcCcsXrw4SfK5z30uRx999A73f/bZZ/Of//mfSZK3vvWteetb35ra2tqsW7cuX//61zN9+vR88YtfzPXXX5/Bgwe3191000156qmnMmzYsHzsYx9r/1zPPPNMrr322syaNSs33XRTrrjiij3wKgEAAAAoIvcA3AltAeD48eN3av///d//TalUyvHHH59LL700tbW1SZIhQ4bkQx/6UIYNG5aVK1fm5z//eXvN8uXLM2XKlCTJlVdeWRE0HnHEEXnve9+bJPnFL36RFStWdMnrAgAAAKD4BIA7YfHixamtrc3IkSN3uG99fX1+97vfJUnOP//8Lbb369cvxx57bJJkxowZ7Y/PnDkzLS0tGTlyZE466aQt6o477rjU1NSktbU1Dz/88G6+EgAAAAB6GwHgDjQ2NmblypUZN25cqqqqdrj/U089lY0bN6ZPnz6ZPHnyVvdpu7pv3rx5aW5uTpL8/ve/T5JMnjw5ffpseVj69euXI444Ikl5STAAAAAA7Az3ANyBRYsWJUlGjhyZH/3oR5k2bVoWL16cPn365IADDsgpp5ySCy64oP2NOebPn58kGTVq1DbfrGP06NFJko0bN2bp0qU58MADs2DBgiTbX2bcVrdkyZKueXEAAAAAFJ4AcAfa7v/3+OOP5/HHH29/R9+6uro8//zzef755zN16tRcc801GTNmTNavX5+k/A6+2zJkyJD2j+vr65Mk69atS5Lst99+O6xrqwEAAACAHREA7kBbADh48OC8733vyymnnJLq6uq0tLRk6tSpufnmm7Nw4cJ89rOfzVe+8pX2cK6mpmabz9m/f//2j1tbW5Nkl+paWlpe2osCAAAAoNcQAO7Aq1/96owePToTJ07MgQce2P54dXV1zjnnnOy///656qqr8qc//Sm//vWv07dv3yTl5b3b0nbfvyTty4T79u2b1tbWnarb1tJiAAAAANicAHAHJk6cmIkTJ25z+6tf/ersv//+Wbp0aebMmdO+TLdtKfDWdN42fPjwJOXlvXV1dduta7tKcMSIEdvcZ968eZk3b95WtzU0NKSqqio1NTVpaGjY5nPQOzQ1NVX8F9hznG+w5zQ1NVWcW20rJTZfMeFnH+havrdB93G+0dnuZjoCwC4wbNiwLF26NE1NTe1h4bJly9La2tp+RWBnS5cuTZIMGjSoPQAcP3586urq2pccb01bXecrETfX3Ny83UHo379/xo0b1/5mJeBNZaD7ON+g6y1btqxidUWbVatWtX9cU1PjZx/YQ3xvg+7jfCNJxo0b1/4+ErtCALgdq1atyv/8z/8kSf76r/86gwYN2mKfjRs3ZuHChUnKB2HSpElJysn8M8880/73zp5++ukkyeTJk1NVVdX+8ZNPPpknn3xyq720tLRk7ty5SZKjjjpqmz3X1NRU3GOws4aGhjQ0NGTx4sU58cQTt/kc9A5NTU1ZsmRJxo4dm9ra2p5uBwrN+QZ7zpgxY7a4AnDVqlUZPnx4qqvLP+rW1tZmwoQJPdUiFJLvbdB9nG90NnPmzN2qEwBux+DBg/PAAw+ksbExRx55ZN7whjdssc/UqVNTX1+fqqqqHH/88Rk7dmwOP/zwzJ07N3fdddcWAeDatWvz4IMPJkle//rXtz9+yimn5NZbb83ixYvz6KOP5rjjjquou++++7Jhw4YMGTJki22dbW/J8tSpU9PQ0JDm5uZthoT0PrW1teYBuonzDbretn4Rqq6ubt/m3IM9x/kF3cf5RpKtrnzYGX26uI9CqampyVlnnZUkufHGG/Pggw+2v2tva2trpk+fnm9/+9tJkjPOOKN9ae473vGOVFVVZfr06bn11lvba5YsWZLPfvazqa+vz5FHHpmTTz65/XNNmDAhp556apLka1/7WubMmZMkKZVKmTFjRm688cYkyaWXXrrddwoGAAAAgM5cAbgDf/VXf5X58+fnySefzL/+679mwIABGTZsWNasWZMNGzYkKS/Jfd/73tde8+pXvzrveMc78j//8z/53//939x2220ZMmRIVqxYkVKplLFjx+YjH/lI+vSpzF+vvPLKLFy4MM8991w+/vGPZ8SIEWlubm5f233mmWfmnHPO6b4XDwAAAMA+TwC4AwMGDMhnP/vZ3H///bnvvvsyb968LF++PIMHD84RRxyR173udTnjjDO2eLOPt771rTn00ENz55135rnnnsuaNWsyfvz4vPa1r82b3vSmDB06dIvPNXDgwFx33XX5yU9+kgceeCBLlixJbW1tJk2alHPPPTennXZad71sAAAAAApCALgT+vTpkzPPPDNnnnnmLtUde+yxOfbYY3eppqamJpdcckkuueSSXaoDAAAAgK1xD0AAAAAAKDABIAAAAAAUmAAQAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBgAkAAAAAAKDABIAAAAAAUmAAQAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBgAkAAAAAAKDABIAAAAAAUmAAQAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBgAkAAAAAAKDABIAAAAAAUmAAQAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBgAkAAAAAAKDABIAAAAAAUmAAQAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIFV93QDAADwkqxZk9x7b/L88+lbX5/hSfoeemhy7rnJ6NE93R0AQI8TAAIAsG+aMyf5l39JHnwwaWlJkvRNMjBJfvvb5LbbkuOOS97xjuTss3uyUwCAHiUABABg3/OrXyVvfnP56r9t2bgx+c1vymHg/vsnf/EX3dUdAMBexT0AAQDYtzz2WHLBBdsP/zprbk4uvTS555492xcAwF5KAAgAwL7lne9M6ut3raalJfmrv0oaG/dMTwAAezEBIAAA+45p05JZs3avdsWK5Ac/6Np+AAD2AQJAAAD2HV//es/WAwDsgwSAAADsO372s5dW//DDSV1d1/QCALCPEAACALBvaGzc9Xv/bc3KlS/9OQAA9iECQAAA9g19++5dzwMAsI8QAAIAsG+ork5GjXppz9G3bzJ6dNf0AwCwjxAAAgCw73j7219a/YUXJkOGdE0vAAD7CAEgAAD7jr/5m56tBwDYBwkAAQDYdxxxRHLOObtXO3lyctZZXdsPAMA+QAAIAMC+5eabk4kTd61m5Mjkxz9Oqqr2TE8AAHsxASAAAPuWMWOSadOSV75y5/YfPbq8/2GH7dm+AAD2UgJAAAD2PQcemPz618nf/V1y8MFb32f//ZPLLku+8Y3y8l8AgF6quqcbAACA3TJoUPldfd/4xmTWrGTevLSsW5f1LS0ZdOSRqTn++PKS39ranu4UAKBHCQABANj3TZ6cTJ6cjU1NqV++PANHj3a/PwCATSwBBgAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBgAkAAAAAAKDABIAAAAAAUmAAQAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIFV707R9OnT09ramsMOOyzjxo1rf/yBBx5Ikhx++OEZO3Zs13QIAAAAAOy23boC8NRTT83rX//63HnnnRWPn3766Vt9HAAAAADoGbsVAA4YMCBJsmjRoi5tBgAAAADoWru1BPiQQw7J008/nX//93/PH//4x4wfPz79+/dv3/7Tn/40S5Ys2a2GPvOZz+xWHQAAAACwpd0KAN/85jdn9uzZefHFF/M///M/FdtKpVJ+9rOf5Wc/+9luNSQABAAAAICus1tLgP/xH/8xf/EXf5E+ffqkVCq1/2nT+bFd+QMAAAAAdK3dugJwwIAB+b//+79873vfy7Jly9Lc3JxSqZSJEyemqqoqn/vc5/L2t7+9q3sFAAAAAHbRbgWA7cXV1Rk/fvwWj48cOTIHH3zwS3lq9pBRo0ZlzJgxWbduXU+3Qg/buHFjhgwZksbGxjQ3N/d0O1BozjfYc1588cU0NTW1/71UKmXAgAFpbm5OS0tLkqSlpcXPPtDFfG+D7uN8o7OJEydm9uzZu1z3kgLAzd10001JkpNPPrkrn5YutGLFiqxfvz4TJ07s6VboYQ0NDVm6dGmGDx9e8SY+QNdzvsGeM3DgwFRXd/xI29TUlNWrV2fw4MGpra1NktTW1mbIkCE91SIUku9t0H2cb3Q2c+bM3arr0gDwne98Z1c+HQAAAADwEu3Wm4DsjJaWltx66615z3vekxNOOCGHHHJIxowZk5tvvjlJMmPGjFxzzTVZsGDBnmoBAAAAAHq9PRIA3n///Tn00EPz9re/PTfddFMee+yxzJ8/P3V1dWlsbEySLFiwINdcc00OO+ywfOpTn8rGjRv3RCsAAAAA0Kt1eQB4zz335Nxzz82CBQtSKpVSKpUyatSoLfbr27dvkvJ9Wq677rr8+Z//eVe3AgAAAAC9XpcGgGvWrMm73/3uNDU1pW/fvvnkJz+ZP/7xj1m6dOkW+/75n/957r333kyaNCmlUil33HFHvvSlL3VlOwAAAADQ63VpAPjd7343S5YsSVVVVW677bZ8/vOfz4QJE7a5/5lnnpmHH344Rx99dEqlUv7t3/4tra2tXdkSAAAAAPRqXRoA3nrrramqqsqZZ56ZCy+8cKdqBg8e3H7l37Jly/Lggw92ZUsAAAAA0Kt1aQA4d+7cJMlpp522S3VnnHFGamtrkyR/+MMfurIlAAAAAOjVujQAbGhoSJIMHTp015ro0yeDBg1KUr4KEAAAAADoGl0aAB544IFJOq4E3Flr167N6tWrkyQjRozoypYAAAAAoFfr0gDwrLPOSqlUyv/93/9l1apVO1333e9+N6VSKUly8sknd2VLAAAAANCrdWkAeOWVV6a6ujqrVq3KxRdfvFMh4G233ZZPfvKTqaqqygknnJCjjjqqK1sCAAAAgF6tuiufbPLkyfn0pz+dq6++Og8++GAOP/zwXHbZZTnmmGPa95kzZ07uuOOOzJ49O3fccUceeeSRlEqlDBgwIDfccENXtgMAAAAAvV6XBoBJ8pnPfCZNTU259tprU1dXl3//939PklRVVSVJvvrVr+arX/1q+/6lUimDBg3KLbfckmOPPbar2wEAAACAXq1LlwC3+dznPpdf/epXOe2001Iqlbb5p6qqKhdddFEee+yxXHjhhXuiFQAAAADo1br8CsA2r3vd63L//ffnj3/8Yx544IE888wzWblyZaqqqjJixIhMnjw5p556ag444IA91QIAAAAA9Hp7LABsc8ghh+SQQw7Z058GAAAAANiKPbIEGAAAAADYO+yxALBUKuUHP/hB/vIv/zJHHnlkRowYkX79+mX06NE55phj8td//de5/fbb09LSsqdaAAAAAIBeb48sAX7iiSfyF3/xF3n22WfbHyuVSkmSurq6rFy5Mk899VRuvvnmjBs3Ll/84hfz9re/fU+0AgAAAAC9WpdfAfjYY4/llFNOybPPPtv+br+DBg3Ky1/+8rz61a/O+PHj06dPn/ZtixYtyl/+5V/m7//+77u6FQAAAADo9bo0AGxoaMhb3vKW1NfXp1Qq5bLLLsuMGTOydu3aPPvss3nsscfywgsvpLGxMb/85S/z3ve+N4MGDUqpVMpXvvKV3HzzzV3ZDgAAAAD0el0aAH7rW9/K/PnzU1VVlRtuuCHf+c53ctJJJ235Sfv0yetf//r853/+Z5544okcdNBBKZVK+cd//MeubAcAAAAAer0uDQBvu+22JMlxxx2XK6+8cqdqJk6cmP/4j/9IkixevDgPP/xwV7YEAAAAAL1alwaAs2fPTlVVVc4999xdqjvvvPPSt2/fJMlTTz3VlS0BAAAAQK/WpQHgunXrkiQjR47cpbrq6uoMHTo0SfldggEAAACArtGlAeCYMWOSJAsWLNiluoaGhqxZsyZJMmjQoK5sCQAAAAB6tS4NAE844YSUSqX88Ic/TGNj407X/ehHP8rGjRuTJEcccURXtgQAAAAAvVqXBoDveMc7kiTz58/PpZdemg0bNuyw5qmnnspHP/rRJMnw4cNz+umnd2VLAAAAANCrdWkAePHFF+eMM85IqVTK7bffnsMOOyzXXnttfv/736e1tbV9v6ampjz88MP5wAc+kBNOOCHLli1LVVVVrrrqqtTU1HRlSwAAAADQq1V39RPedtttOeuss/LYY49l8eLF+fSnP51Pf/rT6du3b4YNG5ZSqZQ1a9a0L/ktlUpJkne96115//vf39XtAAAAAECv1qVXACbJsGHDMn369HziE5/IgAEDUiqVUiqV0tLSkrq6uqxcuTKtra3tj++33365/vrrc+ONN3Z1KwAAAADQ63X5FYBJUltbm2uvvTb/8A//kB/96EeZPn16nnnmmaxatSqlUinDhw/PK17xipx22mm55JJLMmDAgD3RBgAAAAD0enskAEzK9/mbMWNGVq1ale985ztbbP/mN7+ZsWPHuucfAAAAAOxBXb4EOEm+8IUvZMyYMbngggty1VVXbXWf6667Lueee27233//XHvttWlpadkTrQAAAABAr9blAeB73vOe/NM//VPWrVvXfp+/rWnbtmrVqnz605/O+eefn+bm5q5uBwAAAAB6tS4NAH/5y1/mO9/5TkqlUvr3759/+qd/ym9+85ut7nvPPffkqquuytChQ1MqlTJ16tRcc801XdkOAAAAAPR6XRoA/td//VeSZNCgQfnNb36Ta665JkcdddRW933FK16Rq666Kk8++WSOOuqolEqlfO1rX8u6deu6siUAAAAA6NW6NAB8+OGHU1VVlXe84x2ZPHnyTtUcdNBB+c///M8kSX19faZNm9aVLQEAAABAr9alAeCSJUuSZKfDvzYnn3xyBg0alCR59tlnu7IlAAAAAOjVujQAHDhwYJJk9erVu/0c3ggEAAAAALpOlwaAhx12WEqlUu6+++5dqps1a1bq6+uTJOPHj+/KlgAAAACgV+vSAPD//b//lyT5zW9+k89//vM7VdPY2JgPfOADSZKqqqqceeaZXdkSAAAAAPRqXRoAvv/978+BBx6YJPnMZz6TM888M3fccUfWr1+/xb4bNmzIrbfemuOOOy6/+tWv2t88ZNy4cV3ZEgAAAAD0atVd+WQDBw7MHXfckbPOOiurVq3Kr371q/zqV79KdXV1xo8fn1GjRmXAgAGpq6vLc889l5aWliRJqVTK0Ucfna985Std2Q4AAAAA9HpdegVgkrz61a/OjBkzcsIJJ6RUKqVUKqW5uTnz58/P448/nunTp2fOnDlpbm5u3/6Wt7wl9913X4YPH97V7QAAAABAr9blAWCSHHHEEXn44Yfzi1/8IpdeemkmTpzYHva1/ZkwYUIuu+yyPPTQQ/nhD3+YESNG7IlWAAAAAKBX69IlwJt7wxvekDe84Q1JkpaWlqxevTrNzc3Zb7/9MmDAgD35qQEAAACA7OEAsOITVVdn1KhR3fXpAAAAAIDsoSXAAAAAAMDeQQAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYNU93QAAAHSFxx9/PC0tLVmzZk1OO+20nm4HAGCv4QpAAAAKoaWlpf0PAAAdBIAAAAAAUGACQAAAAAAoMAEgAAAAABSYNwEBAGCfdfbZZ1f8vampKcuXL895552X/v3791BXAAB7F1cAAgAAAECBCQABAAAAoMAEgAAAAABQYO4BCABAIdTW1iZJampqergTAIC9iwAQAIBCOPvss9PQ0JD58+f3dCsAAHsVS4ABAAAAoMAEgAAAAABQYJYA76Tly5fnJz/5SR5//PHU1dWlVCpl1KhRefWrX52LL744o0ePrtj/+uuvz6xZs7b7nB/84Adz5JFHVjzW1NSUKVOm5L777suiRYvSp0+fjB8/PqeffnrOPffc9O3bt8tfGwAAAADFJQDcCbNnz85nP/vZ1NfXp6qqKiNGjEhjY2MWLlyYhQsXZtq0afnnf/7nvPzlL2+vmTVrVhYuXLjd521oaKj4e2NjY6655po89dRTSZJhw4alT58+mTt3bubOnZvp06fn6quvTr9+/br+RQIAAABQSALAHWhqasoXv/jF1NfX5+ijj8773//+7L///kmS5557Ll/+8pezYMGCXHfddbnhhhtSU1OT1tbWLF26NKNHj863v/3tnf5cN910U5566qkMGzYsH/vYx3L00UcnSZ555plce+21mTVrVm666aZcccUVe+S1AgAAAFA87gG4A7/+9a+zcuXKDBkyJJ/85Cfbw78kOfTQQ/MP//AP6dOnT5YsWZKHH344SXm5cEtLS8aPH7/Tn2f58uWZMmVKkuTKK69sD/+S5Igjjsh73/veJMkvfvGLrFixoiteGgAAAAC9gABwB9ru43fcccdl0KBBW2w/6KCDMm7cuCTJnDlzkiSLFy9OkvbHd8bMmTPT0tKSkSNH5qSTTtpi+3HHHdd+dWFb0AgAAAAAOyIA3IGVK1cmScaMGbPNffr0Kf9vbGlpSbJ7AeDvf//7JMnkyZPbn6+zfv365YgjjkhSXhIMAAAAADvDPQB34OMf/3haW1tTU1Oz1e3z589vf7OPCRMmJOkIAJPky1/+cp544omsXbs2gwYNyuGHH57zzz8/xx57bMXzLFiwIEm2u2y47Z2GlyxZsvsvCAAAAIBeRQC4A7W1tdvctmLFinzxi1/Mxo0bM2jQoLzuda9L0hEA3nTTTUnK7+Y7ZMiQrFq1Ko888kgeeeSRnHfeebn88stTVVWVJFm3bl2SZL/99tvm5xsyZEiSpL6+/iW/LgAAAAB6BwHgbiiVSvnlL3+Zm266KevWrUt1dXU+9KEPZejQoUk6AsDJkyfn8ssvzyGHHJIkqaury/e+973cd999ufvuuzN69Oi85S1vSdIR6m3rSsMk6d+/f5KOpcYAAAAAsCMCwF307LPP5lvf+lb7ffhGjx6dD3/4wznqqKPa97n00kvT2tqaE088sSLQGzlyZD70oQ+ltbU106ZNy49+9KO86U1vSnV1dfr27ZvW1tZs3Lhxm5+7ubk5Sfl+gAAAAACwMwSAO6m+vj433XRT7r333pRKpdTU1OSiiy7KW9/61gwYMKBi35NPPnm7z/XGN74x06ZNS319fRYsWJCXvexlGTJkSOrq6rJ+/frt9pAkI0aM2OY+8+bNy7x587a6raGhIVVVVampqUlDQ8N2e6T4mpqaKv4L7DnON+g+zjfoHs416D7ONzrb3UxHALgTlixZkquuuqp9ae8pp5ySd77zndl///136/mGDRvW/nHbCTx+/PjU1dVVvIHI5pYuXZokOfDAA7e5T3Nz83YHoX///hk3blzmz5+/q21TUN5UBrqP8w26j/MNuodzDbqP840kGTduXPv7SOwKAeAONDY25uqrr87ixYszdOjQfPjDH85rXvOabe4/Y8aMPPbYY5kwYULe9KY3bXWftnf8TdIeIk6ePDlPPvlknnzyya3WtLS0ZO7cuUlSsdx4czU1Ne33CtxcQ0NDGhoasnjx4px44onbfA56h6ampixZsiRjx47d7pvdAC+d8w26j/MNuodzDbqP843OZs6cuVt1AsAd+MUvfpFFixalf//+ufrqq3PooYdud//Gxsbce++9GTRoUM4888wMHjx4i33uvPPOJMmRRx7Z/q6/p5xySm699dYsXrw4jz76aI477riKmvvuuy8bNmzIkCFDttjW2cSJEzNx4sStbps6dWoaGhrS3Ny8zZCQ3qe2ttY8QDdxvkH3cb5B93CuQfdxvpF0vD/ErurTxX0UzkMPPZQkufDCC3cY/iXJSSedlOHDh6e+vj6f/exnK672W7duXb7+9a9n9uzZqaqqyqWXXtq+bcKECTn11FOTJF/72tcyZ86cJOV3HJ4xY0ZuvPHGJOU3GNneOwUDAAAAQGeuANyOUqmU5557Lkly//33Z8aMGdvd//zzz88FF1yQT3ziE/nc5z6Xp59+On/7t3+b4cOHp6amJitWrMjGjRtTVVWVd7/73Tn66KMr6q+88sosXLgwzz33XD7+8Y9nxIgRaW5ubl/bfeaZZ+acc87ZMy8WAAAAgEISAG7HunXr0tLSkiRZsWLFDvdfu3ZtkmTSpEm54YYbcscdd+SRRx7JkiVLUlVVlTFjxmTSpEm54IILtno14cCBA3PdddflJz/5SR544IEsWbIktbW1mTRpUs4999ycdtppXfsCAQAAACg8AeB2DB06tP1+fbtq+PDhueyyy3LZZZftUl1NTU0uueSSXHLJJbv1eQEAAACgM/cABAAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBgAkAAAAAAKDABIAAAAAAUmAAQAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBgAkAAAAAAKDABIAAAAAAUmAAQAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBgAkAAAAAAKDABIAAAAAAUmAAQAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBgAkAAAAAAKDABIAAAAAAUmAAQAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBgAkAAAAAAKDABIAAAAAAUmAAQAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBgAkAAAAAAKDABIPRSU6dOzUMPPdTTbQAAAAB7mAAQeqmmpqY0Nzf3dBsAAADAHiYABAAAAIACq+7pBgAAANhH/PrXyX/9V341Y0Za6uszb8iQnHP22ckVVyRHHtnT3QGwDQJAAAAAtu+OO5Jrrkl++9skScumh1uS5Omnk69+NXn965MvfCE56aSe6hKAbRAAQi8xZcqUNDU1tf/90UcfzZo1a3L33XentrY2SVJbW5uzzz67p1oEAGBv9G//lnzsY0mptP397r+/HAL+7/8m/+//dU9vAOwU9wAEAABg677zneSjH91x+NemoSF529uSX/1qj7YFwK4RAAIAALClNWuSD3xg1+uampLLL9/50BCAPc4SYAAAALZ0881JfX2SZEqSpk6bfrOV3WuTtN9MZu7cZOrU5A1v2KMtArBzXAEIvVR1dXWqq/0bAAAA2/CNb7y0+q9/vWv6AOAl89s/9FKvetWrsnz58p5uAwCAvdELLyRz5mxz8/OdPj5hWztNndqVHQHwErgCEAAAgEqrV293c2unP9u0fn3S0tJ1PQGw21wBCAAAQKXa2u1u7rszz9G3b/kPAD1OAAgAAEClsWOTmpqkuXmrm1++M89x4IFJVVWXtgXA7rEEGAAAgEpDhyYXX/zSnuOyy7qkFQBeOlcAAgAAsKW/+ZvkBz9Ikpy9nd0u2NqD1dXJ+963J7oCYDe4AhAAAIAtnXZacsI23+N3+97+9mT8+K7tB4DdJgAEAABg626/PTnooF2rOf745Bvf2DP9ALBbBIAAAABs3QEHJA89lEyatHP7n3lmcu+9ycCBe7YvAHaJABAAAIBtmzAhefzx5HvfS04+OUlS2+lP+vRJzjsvueuuZMqUZNiwHmwWgK3xJiAAAABsX79+yaWXlv88+WROf/LJrJw/PyMOOSQ58cTkZS/r6Q4B2A4BIAAAADvvla/MxsMOy9r587PfhAlJ//493REAO2AJMAAAAAAUmAAQAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBg1T3dAN1r1KhRGTNmTNatW9fTrdDNXnzxxTQ1NbX/vVQqZcCAAWlubk5LS0uSpKWlxWzAHrBx48YMGTIkjY2NaW5u7ul2oNCcb9A9nGvQfZxvdDZx4sTMnj17l+sEgL3MihUrsn79+kycOLGnW6GbDRw4MNXVHad8U1NTVq9encGDB6e2tjZJUltbmyFDhvRUi1BYDQ0NWbp0aYYPH57+/fv3dDtQaM436B7ONeg+zjc6mzlz5m7VWQIMAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACiw6p5uAOgBq1alavXq9F29Ohk8OKmt7emOAAAAgD1EAAi9RUNDcu+9yd13J/PmpSbJ2CSlPn2Sk05KzjsvOf74nu4SAAAA6GICQOgNfvSj5LLLkvr6LTZVbdyYzJhR/jNxYvLLXyaHHNLtLQIAAAB7hnsAQtF9+9vJW9+61fBvC/PmJSefnDz77J7vCwAAAOgWAkAosl/9KrniiqRU2vmaJUuSc89N1q/fY20BAAAA3UcACEX2z/+ctLTset3zzyff+17X9wMAAAB0OwEgFNXTTyf337/79V//etf1AgAAAPQYASAU1be+9dLqn3oqmT69a3oBAAAAeowAEIrq6adf+nPMmfPSnwMAAADoUQJAKKqdedffHfFGIAAAALDPEwBCUQ0Z8tKfY+jQl/4cAAAAQI8SAEJRveY1L/05jj32pT8HAAAA0KMEgFBU73tf0rfv7teffHJyzDFd1w8AAADQIwSAUFQHHZRccMHu1//t33ZdLwAAAECPEQBCkV1zTTJo0K7XnXhicsklXd8PAAAA0O0EgFBkxxyT/PCHSf/+O18zaVJy551Jbe2e6wsAAADoNgJAKLpzz03uu6+8JHh7qqqSP/uzZPr0ZMyY7ukNAAAA2OOqe7oBoBucfHJy443JI48kd9+dPPZY0tiYUpLst1+qzjijHBROmJDst18PNwsAAAB0JQEg9CbHHNP+zr5NL76Y5XV1Gb3//qm13BcAAAAKyxJg6K2qq5M+vgQAAADszaZOnZqHHnqop9tgH+e3fwAAAIC9VFNTU5qbm3u6DfZxAkAAAAAAKDABIAAAAAAUmDcB2QutWrUqP/7xj/Poo49m2bJlGThwYF7+8pfnvPPOy/HHH9/T7QEAAACwDxEA7mUWLVqUT33qU1m5cmX69OmTESNGZMOGDXnsscfy2GOP5eKLL8673vWunm4TAAAA2AOmTJmSpqam9r8/+uijWbNmTe6+++7U1tYmSWpra3P22Wf3VIvsgwSAe5FSqZRrr702K1euzGGHHZaPfexjGTt2bDZu3Jj7778/N9xwQ3784x/nsMMOyymnnNLT7QIAAACwD3APwL3IQw89lD/96U+pra3NJz/5yYwdOzZJ0qdPn5x55pnt6f4tt9zSk20CAAAAsA8RAO5FHnrooSTJiSeemFGjRm2x/bWvfW2S5IUXXsif/vSnbu0NAAAAgH2TAHAvUSqV8tRTTyVJXvnKV251n1e84hWpqalJkjzzzDPd1hsAAADQM6qrq1Nd7Q5uvDQCwL3EqlWrsm7duiTJAQccsNV9ampqst9++yVJFi9e3F2tAQAAAD3kVa96VSZNmtTTbbCPEwDuJdavX9/+8bBhw7a53+DBg5Mk9fX1e7wnAAAAAPZ9AsC9ROcAsO1tvbdmwIABSZLW1tY93hMAAAAA+z6LyPcSndfzb9y4cZv7NTc3J0n69eu3W59n+OzZ5YDxyCOTAw/s2LBgQTJ/fvnjP/uzyqJf/zrZuDE56KBkwoSOxxctSv7wh/LHJ5+c9OmUJ//mN0lzczJ+fPKyl3U8vnRp8txz5Y9POCHZdE/DJMljjyUNDcn++yeHHtrx+IoVSds9D1/zmqR//45tv/tdUl+fjBqVHHFEx+MrVyZPP13++FWvSgYN6tj2+98n69Ylw4cnnS+jXrMm2XQfxrzylcnQoR3bZs1KVq8uP9b5Ho3r1ydPPFH+ePLkZNMS7STJnDlJXV0yeHByzDEdj2/YkDz+ePnjI49MRo7s2Pbss8myZcmAAcmxx3Y83tSUPPJI+ePDDkvGjOnYNm9esnhxUlubHH98x+OtrcnDD5c/njgxnQ1YujSDly5N1Zo1KY0e3bGhVEqmTy9/fMghSefl6G0zUlWVbHpDmnY9PSPLlydz55Y/3nxGfvvb5MUXu35Gjj46GTKkY1vbjAwblhx1VMfje8OMPP98smTJljPS0pLMnFn++OUvTza983iS5I9/TBYuTKqrkxNP7Hi8VEpmzCh/3FMzsmRJ+TUlW87Io48mjY3bn5Hjjks6fw1tm5HRo5PDD+94vPOMvPrVycCBHdvaZmTEiOQVr+h4fDszUvvss6l64YXysdmTMzJ3bvn1bj4jjY3l/z9J+XV2PvfbZqRfv/L/nzZ7w4wsXFj+XMmWMzJzZrnH7c3IiSeWe2zTNiNjx5ZfU5u9YEby1FPl7Zt/HVm3rvx8yZYz8vTT5T42n5EXXyz3nZQ//4gRHdvaZmTgwHLfbfaGGZk/vzwnW5uRGTPKtdubkc1r2mbkgAPKn6vN3jAjTzxRPv83n5HVq8vfU5Ldm5Gjjipvb9M2I0OGlJ+vzd4wI3/4Q/n7wOYzsnFj+WtCsu0Z6dOn/DWhs7YZmTChPCdtNp+RqqqObd01I48/Xv7avfmM1NWVv9Yn5a/Zm/6xP0nHjIwcWf5a36bzjBxzTPn8b9M2I/vtV/560aarZ+SZZ1K1cGH6rV1beT5ub0aee678c97mM9LcXP6en2x7Rmpqyt/z23SekZe9rPx9oM3eMCOPPFL+2WzzGVm2rPyzXFL+mazzhR9tMzJmTPlnuTZ7w4zMnp2sWrXljNTXl38fS7Y6I1mxYsuvIw0N5Z/pk23PSP/+5Z/p23SekUMPLf+c12ZvmJGHHy7/7rX5jCxeXP5dLUlOOinp27djW9uMjBtX+bvaphnZb9asLD/kkJQ6/Zw7av78jKirS2nUqNR3fj1dPSNPPpmsXbvljKxdW96WdO2MDBpU/n2sTecZOeKI8u9xbfaGGWn7fXnzGXnhhaTtzVo3z1TaZuTAA5ODD+54fDdnZNhTT6Wh8+86O6vEXmHhwoWlCy+8sHThhReW5syZs8393ve+95UuvPDC0g9+8IOtbn/++edL995771b/3HXXXaVS+ctZqelznytt2LCh/U/TNdeUSklpY9++FY9v2LChtHHQoFIpKTV/8pOVNV/6UvvzbVi1qrJm//3LNe9/f2XNN7/ZUbNgQcW21okTyzV//dcVjzd+73vtNQ1PP11Zc/TRpVJSarnkksqaH/+4o+aRRyprTj65XHPeeRWPN9x7b0fN/fdXbGs5++xyzamnVtb8+tftNY0//WllzcUXl0pJqfXYYytrnnyyo+b736/Y1vyXf1muOeKIyuMwb15Hzbe/XVlzxRXlY3fAAZU1y5Z1HO+vfrV01113lW677bbSbbfdVpqzqbeGgQNLt956a/vjd915Z0fN5z9feeyuvrr8eaqrt5yRgQPLx+5Tn6qs+dd/7Tjeq1dX1owZU675wAcqa77xjY6aF16oPHYve1m55t3vrjze//3fHTVz5lTWvPKV5WP31rdW1tx+e8fxfvTRypqTTirXnH9+5bGbMqWj5le/qjzeZ51VrjnttMqaGTM6jt3PflZZ8+Y3l4/3a15TWfP733fU3HprZc2ll5Zrjjyy8jg8/3xHzXe+Uzkjl19ePnYHHlhZs3Rpx/H+2tcqa/7+78s1w4dX1tTXd9R84QuVx+6qq8o1NTVbzsiAAeVj94//WFnzxS92HLs1ayprRo8u13zwg5U1X/96R83ChZXH7pBDyjXveU/l8b755o6aZ56prDnqqPKx+//+v8qa227rON6PPVZZc+KJ5ZoLLqis+cUvOmqmTWt/fM2aNaX1f/Zn5ZrTT6883g891HHs7r678ni/6U3l433ccZU1TzzRUfODH1TWvOMd5ZpXvKLyODz33I5n5KCDKmuWLOk43v/xH5U1H/lIuWbEiMqa9es7aq69tvLYfeYz5Zra2i1npH//cs2nP11Zc911Hcdu7drKmlGjysf7Qx+qrLnhho6aRYsqj93BB5dr3vveymP33e921MydW1kzeXL52L3tbZU1P/pRx/H+7W8ra044Yesz8vOfd9Q88EDlsTvjjHLN619febwffLDj2N1zT2XNhReWj/fxx1fW/O53HTU//GFlzdvfXq6ZNKnyODz7bEfNTTdVHu/3va987CZMqKxZvLjjeF9/fWXNhz9crhk5srJm3bqOmn/5l8pj90//VK7p12/LGenXr1zzT/9UWfMv/9Jx7NatK61Zs6b0zDPPlNasWVPaOHJk+Xh/+MOVNddf31GzeHHl55kwoVzzvvdVHrubbuqoefbZyuM9aVL52L397ZU1P/xhx/H+3e8qa44/vlxz0UWVNffc01Hz4IOVx+71ry/XnHFG5fF+4IGOY/fzn1fWXHBB+XifcEJlzeOPd9T86EeVNW97W7lm8uTK4zB3bkfNd79bebzf+95yzcEHV9YsWtRxvG+4obLmQx8qH+9Roypr1q7tqLnuuspj9+lPl2v6999yRmpryzWf+UxlzbXXdhy79esra0aMKB/vj3yksuY//qOjZsmSypqDDirXXH555bH7znc6ap57rvJ4v+IV5WP3jndU1vzgBx3H+4knKmuOO65c86Y3VdbcfXdHzfTplcfu9NPLNWeeWXm8p03rOHa/+MXWZ+TEEytrHnuso+a22ypr/uIvyp//8MNLazp//37mmY6am2+uPN7veU/58xxySOWxW7iw43h//euVNR/8YPl4jx5dWbNmTUfNF79YWfOP/1iuGTBgyxmpqSnXXHVV5fH+whc6jl19fWXN8OHl4/33f19Z87WvddQsXVpZc+CBO56R55+vPN5HHlk+dpdeWllz660dx/v3v6+sec1ryjVvfnNlzc9+1lEzY0blsTvttHLNG95Qebx/9auOmilTKmvOP7987E46qbLm0Uc7jvftt1fWvPWt5ZpXvrKyZs6cjpr//u/KY/fud5drXvayymP3wgsdx/sb36is+cAHysd7zJjKmtWrO2r+9V8raz71qXLNwIFbzkh1dbnm6qsrj/fnP99x7F58sbJmv/3Kx/ujH62s+epXO2qWLausOeCAcs0VV1Qeu29/u73mZzfe2P572q233lpaOXZsqZSU/vj615d/d7vrrnLN97/fceyefLJyRo49tny8L7648vP89KcdNb/+deWxO/XUcs3ZZ1ceu/vv76i5997KmvPOKx+7k0+urHnkkY7j/eMfV9Zcckm55uijK2uefrqj5nvfqzx273pXuWbixMpjt2BBx/H+5jcra97//vLx3n//yppVqzpqvvSlyppPfrJcM2jQljPSt2+55pprKo/35z7Xcbw3rxk2rHy8P/axypqvfKWjZvnyyprx48s1V15ZeexuvLFUSkp33XVX6d57792l3MkVgHuJ/fffP9XV1WlpacnixYtzROcrlTZpbW3NihUrkiQHdr56r5Pm5uY0NDTs8POtXr06q9qu+EsyYvXqtOXq8zs9niSHlkqpSrJmzZrUddq236pVabvGaMGCBSl1+lfOia2tqU6ybt26LO9UM7SuLm3/pvfCCy9k44svtm87pKUltSkvh17WqWbwihVpy+IXLlyYlk5Xf0xoakr/JPUvvpglnWoGLV+etn8rXrx4cZo6Xc13UGNjBiTZsGFDFnWqGbB0adry+6VLl6ah07YDNmzIoCSNDQ15odPj/ZYsycGbPl62bFle7LRt3IsvZkiSpqamiv+nNYsWpe06lRUrVmR9p23719dnWMrHsXNN32XL0vZvh3UrVmRdp22j16/P8CQtra0VNVXr16ft3w5XrlyZZYMHt19B+mKn/++rVq3q6K3Tv1zukRnp9K+cbTOydt26rNjejHS63+U2Z6Surn1GFi1alJZO/yJ3cFNT+mUnZqTTFRbtM/Liizs/Iw0Nuz4jGzbscEaWr1iR+p2ZkaVLtzkjY9avz37Zckb6rF+ftn83WrlyZdZ02jZq7dqMSPmK5IrjvXFj2q5b6OoZmT9/fsW/hG9zRlaurJyRTrdQaJ+RdesqZmRIXV3Gbfp40aJFaenUW/uM1Ndvf0Y6/cvoQU1Nuz4jm/67vRlZumxZNmxlRhqbmrJgWzOyfPlOzUj10qVp+7fDurq6yhlZt27rM7Ju3a7PSGvrDmekVCptd0ZWdp6R1asrZ6TTv4S3z8jatRUzMmzlyrT9u+8LL7yQjZveZCtJXtbSkj7ZiRkpldq3HdzcvHMz0unqrvYZ2ZXvNZu+jjQ0NGThtmZk6dKKGRm/YUMGZ9dmZGx9fYZmKzOyZMmuz8jatTuekc1q0tLSPiOrVq/O6l2dkdWrtz8jm76XLVmyJINaW9M3OzEja9e2b3tZa2tqshMz0mnFxs7MyKJFi9Lc6aqMthl5ccOGLN7GjCxZsiSNOzEj/ZcuTds1WDs7I7WLF+eQTR/v9IwsXrzDGWltaamckTVrdjgjrZvPSHPztmdkzZpdnpHhq1en7Rqj+fPnV1xh8fKNG3duRtasad+20zPS6ZY9bTOyvr4+S7c3I51WMWxzRpYt2+aMHNjQkIHZxRl58cXdnpG2HtpUL1q0468jm8/I6tXtM1K3cmXWdp6Rdeu2PiNNTR0zsmpVxYyMXLMmI7P1GWn72XiHM9Lp942dnpFOPye0z8hmP7MOWbGifUYWLlyY1paOn0i2OSMrVlTOSKffudp+F9p8RgYuW5a23xa3OSMbNmxzRpZta0YaG3d+Rl58sfx1ZLOfc6sXLmyfkRV1dRW/C7X/zLr5jKxa1TEjdXU7NSNVTU3tx3uPzEin3zd2ZkYWLFiQ0lZmZN369RW/L3eekbq6urzY0vmn1rKGhoYsX748NTU1mT9/fsXvy4sWLUpzp5+n22fkxRe7dkY2+5m1/XvNbszI5r8LVczI5r8vr1+fYdnKjKxcuc0ZGb1uXYZnKzPS2LhnZ6STthlZs3Ztxe9CW8xIp1Vp25yRTt9rdlVVqdTpJ1x61Cc/+cnMmjUrZ599dv7u7/5ui+1z5szJxz/+8fTp0yf//d//naGdl6huMm/evMxru4R0Mw0NDRnx9NMZMGBAXnHOOVssAa5asCBJUtps+UzVww8nGzemdOCBWyzdq9p0GXTppJMqvlFWPfJI+9K9UufLoJcuTdWmS+VLxx9f8Ytc1eOPty/vLHW+VH7FilRtWk5ROvbYiuWdVU880b4EuLTZkpuqTZdBl445pmJ5Z9WTT7Yv7yxttiyratNl0KWjjqpYAlw1e3b7EuDSZkv3qjZdKl+aNKliWVbVM8+0L90rdb4MesOGVG1aTlE64oiKpXtVzz3Xvryz1PlS+aamVG1aTlE69NCK5Z1Vf/hD+xLgUuflFK2tqdq05Kb0spdl6qxZaWpqSlL+gl+zbFnW1ten+TWvaV+CXltTkzds+n9VOvjgLZbuVW1allXa7DLoHp+R5ctTtWk5xRYz8rvftS8B7tIZeeUrK5Zltc/IsGEpdb5Ufm+YkXnz2pcAlzZbllW16VL50sSJFUtuqv70p/ale6XOl8qXSqnadKl8j83IkiXl15StzMhjj7UvAd7mjLzmNRXLstpnZPTolDovuek8I696VcXSvfYZGTEipc7LKbYxI01NTVn54IMZXVOT6pEj9+yMPPts+xLg0mZL96o2LacoHXZYxZKb9hnp16/8/6fN3jAjCxeWP1e2MiO/+U37EuBtzsgJJ1Qsy2qfkbFjy6+pTQ/PSJLy45uWd5Y2W5ZVtWnJzRYzMmdO+xLg0mZL96o2LbkpHXlkxZKb9hkZOLDcd5u9YUbmzy8vld/ajPz610mptP0ZOfnkNDU3Z8mSJRk7dmz6/e537Uv3Sp2X3OwNM/L737cvAS5ttiyravbscs3uzMjkyRXLstpnZMiQ8vO12Rtm5I9/bF8CXNpsWVbVptuYbHNG+vQpf03opH1GDjpoi6V7nWek8y/u7V9H9vSM/Pa37UuAS5st76zadKub0qtfXbF0r31GRo4sf61v03lGjj66Yule+4zst1/560Wbrp6RuXPTsmRJVrz4YoafcUbHPcy3NyPPP9++BLi02dK9qk23MdnmjNTUlL/nt+k8I4ccssXSvR6fkUcfbV8CXNps6V7VplvdlI47ruIfPttnZMyY8s9ybfaGGXn66fblnRUzUl9f/n0sW5+RtiXApc2Wd1Ztuo3JNmekf//yz/RtOs/Iy19esbxzr5iRmTPblwCXNlveWbXpVjelE0+s+MeH9hkZNy6lzrcx2TQjjz76aJYdfHD7EuCWlpb0feKJ7NevX1pGjEj9+PGpra3NWWed1fUz8tRT7UuAK2Zk7drytnTxjAwaVP59rE3nGTn88IolwHvFjGy6jckWM/LCC6naFNRtkalsmpHSAQdssQR4d2bk6TvvzMJDDkn//v3LM7CTBIB7kbvvvjvf/OY3079//3zrW9/Kfp3v8ZPk3/7t3zJt2rQcd9xx+cxnPrPLzz916tQ0NDTs8pBQDFOmTGkPAJNyILF8+fKMHj26/Ye22tranH322T3VIhRWQ0ND5s+fnwkTJqR/53tUAl3O+Qbdw7kGe47f3die3c12+ux4F7rLWWedlXHjxqWhoSHXXntt+3Lfpqam3HLLLZk2bVqqq6vzV3/1Vz3cKQAAAAD7CvcA3IvU1tbmE5/4RK666qo8/fTTec973pORI0dm7dq1aWxsTJ8+fXLFFVfkkM7LnAAAAABgOwSAe5mJEyfmK1/5Sn74wx/m0UcfzapVqzJkyJAce+yxufjii3Nk53vEAAAAAMAOCAD3QiNHjswVV1zR020AAAAAUADuAQgAAAAABSYABAAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBgAkAAAAAAKDABIAAAAAAUmAAQAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBgAkAAAAAAKDABIAAAAAAUmAAQAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBgAkAAAAAAKDABIAAAAAAUmAAQAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBgAkAAAAAAKDABIAAAAAAUmAAQAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBgAkAAAAAAKDABIAAAAAAUmAAQAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIEJAAEAAACgwASAAAAAAFBgAkDopX73u99l9uzZPd0GAAAAsIcJAKGXamlpSUtLS0+3AQAAAOxhAkAAAAAAKDABIAAAAAAUmAAQAAAAAAqsuqcbALrH2WefXfH3pqamLF++POedd1769+/fQ10BAAAAe5orAAEAAACgwASAAAAAAFBglgADAAAA7G3+9Kdk6tT0XbQoI+vr03f48OToo5PTT09qa3u6O/YxAkDopWpra1NTU9PTbQAAANDZzJnJ97+fzJ6dJOm76U+S5KGHkptuSs46qxwGjh3bU12yjxEAQi911llnZf78+T3dBgAAAG2uvTb5zGe2v8+GDclddyUnnZT8/OfJkUd2T2/s09wDEAAAAKCnfe1ryac+tfP7/+lPyRvekCxcuOd6ojAEgAAAAAA96U9/Sj7ykV2ve+GF5IMf7Pp+KBwBIAAAAEBP+s//TFpbd6/2jjuSRYu6th8KRwAIAAAA0FOampJvf3v361takm99q+v6oZAEgAAAAAA95ZFHkmXLXtpz/PSnXdMLhSUABAAAAOgpdXUv/TlWrnzpz0GhCQABAAAAekrfvnvHc1BoAkAAAACAnjJu3N7xHBSaABAAAACgpxx7bHLkkS/tOd7+9q7phcISAAIAAAD0pCuv3P3aoUOTSy/tul4oJAEgAAAAQE965zuT4cN3r/bd704GD+7afigcASAAAABATxo2LLn99qS2dtfqXve65Npr90xPFIoAEAAAAKCnnX568tOfJgMH7tz+b3xj8rOfJf367dG2KAYBIAAAAMDe4A1vSL71reTP/7x8VeDWTJqUfPKT5bBwyJDu7Y99VnVPNwAAAADAJqNHl+8J+Pa3J488kpZFi/Li6tUZOGZMqo85Jjn44PJS4WqRDjvPtAAAAADsbWpqkte+NhubmrJu+fL0Hz161+8RCJtYAgwAAAAABSYABAAAAIACswS4lxk1alTGjBmTdevW9XQr9LCNGzdmyJAhaWxsTHNzc0+3A4XmfIPu43yD7uFcgz3nxRdfTFNTU/vfS6VSBgwYkObm5rS0tCRJWlpa/F7fS02cODGzZ8/e5ToBYC+zYsWKrF+/PhMnTuzpVuhhDQ0NWbp0aYYPH57+/fv3dDtQaM436D7ON+gezjXYcwYOHJjqTm/w0dTUlNWrV2fw4MGp3XQPwNra2gzxDsC90syZM3erzhJgAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAADYS/3ud7/L7Nmze7oN9nECQAAAAIC9VEtLS1paWnq6DfZxAkAAAAAAKDABIAAAAAAUmAAQAAAAAAqsuqcbAAAAAKDs7LPPrvh7U1NTli9fnvPOOy/9+/fvoa7Y17kCEAAAAAAKTAAIAAAAAAVmCfAONDY25q677sqMGTOyZMmSNDQ0ZL/99ssrXvGKXHTRRTniiCO2qJkyZUp+/OMfb/d5zz333Fx00UVbPD5z5szcddddmT9/fjZs2JDRo0fnxBNPzMUXX5yhQ4d22esCAAAAoHcQAG7H2rVr88lPfjILFixIkgwZMiRDhw7NihUr8uCDD2b69On5m7/5my3W5z/77LNZuHDhDp97c9/97ndz++23J0kGDBiQIUOGZNGiRbntttsybdq0/PM//3MOPPDALnp1AAAAwN6utrY2NTU1Pd0G+zgB4HZcf/31WbBgQcaMGZOPfOQjmTRpUpJk5cqV+eY3v5mHH3443/zmNzNp0qSKYG7x4sVJkm9961sZO3bsTn2u6dOn5/bbb0+fPn3y3ve+N+ecc0769u2burq6fOlLX8qsWbPyxS9+MV/+8pfTt2/frn+xAAAAwF7nrLPOyvz583u6DfZx7gG4DXV1dfnNb36TJBXhX5KMGDEiH/3oRzN27Ni0tLTkzjvvrKhdvHhxqqurM3r06J36XKVSKbfcckuS5Lzzzsv555/fHvKNHDkyH/3oR1NdXZ0//vGPmT59ele8PAAAAAB6CQHgNsyaNSsbN27MqFGjKsK/NrW1tTnmmGOSJM8880z7483Nzamrq8v++++/01fq/elPf2pfZnzeeedtsX3kyJHt9xqcMWPGLr8WAAAAAHovAeA2rFy5MkkyZsyYbe7Tp0/5f19LS0v7Y4sXL87GjRszfvz4nf5cTz75ZJLylYXbusffK1/5yiSVYSMAAAAA7Ih7AG7DBRdckDe+8Y3bvIqvsbExjz/+eJLkoIMOan+87f5/Q4cOzc0335yHH344y5YtS01NTSZMmJDXv/71Ofvssyuet20t//ZCw7Ygsq6uLk1NTamtrX1pLxAAAACAXkEAuA3V1dWprt76/57m5uZ89atfzdKlS5Mk55xzTvu2tgDwl7/8ZZJk4MCB2W+//VJXV5c5c+Zkzpw5uf/++/OZz3wmgwcPTpKsW7cuSTJs2LBt9tO2b5LU19cLAAEAAADYKQLAXfT000/nhhtuaL9q7y1veUte9apXtW9vCwBHjx6dK664Iq95zWvSp0+fNDY25s4778z3v//9zJkzJ1/60pdy9dVXJykHekm2G+oNGDCg/ePW1tYuflUAAAAAFFWvCAB3NTCrqqpqv79fm7q6utx8882ZNm1aSqVS+vXrl3e9611bvGnHaaedlsmTJ2fSpEkZNWpU++P9+vXLJZdckqFDh+aGG27I448/nmeffTaHHXZY+5WGGzdu3GZPzc3NFc8FAAAAADujVwSAl19+eZYtW7bT+5933nm54oorkpRDuTvvvDO33HJLGhoakiSvfe1r8653vSv777//FrVbe8fgzs4444z813/9V5qamvL000/nsMMO22Ip8NasX78+Sfkqwc7LgTc3b968zJs3b6vbGhoaUlVVlZqamvbXQu/V1NRU8V9gz3G+QfdxvkH3cK5B93G+0dnuZjq9IgDcXY2Njbnuuuvy6KOPJkkOPfTQvOc979lhyLc9NTU1GTBgQJqamtqv6jvggAOSdCwf3pq2+w2OHz8+VVVV29yvubl5u4PQv3//jBs3rn0JMyxZsqSnW4Bew/kG3cf5Bt3DuQbdx/lGkowbN267F5BtS68IAG+88cbdqrv++uvz6KOPpk+fPnnnO9+ZN73pTVssDe5s/vz5ueOOO9K3b99ceeWVWw3q1q1blzVr1iRJxo4dm6TjqsHFixdnxYoVFUuH28yePTtJ8spXvnK7PdfU1KR///5b3dbQ0JCGhoYsXrw4J5544nafh+JramrKkiVLMnbsWG8qA3uY8w26j/MNuodzDbqP843OZs6cuVt1vSIA3B1/+MMfMm3atCTlJcTnnnvuDmsGDBiQqVOnplQq5c/+7M9yzDHHbLHPHXfckaR8JV7b9smTJ2fkyJGpq6vLXXfdlXe9610VNS+88EKeeOKJJMnpp5++3R4mTpyYiRMnbnXb1KlT09DQkObm5m2GhPQ+tbW15gG6ifMNuo/zDbqHcw26j/ONpPI9InbFti9n6+UefPDBJMmRRx65U+FfUn7n3+OOOy5J8uUvfzm//e1vUyqVkpQP0D333JPbb789SXLxxRe338uvb9++edvb3pakHBBOmTKlvW7evHn5/Oc/n40bN+Z1r3tdDjvssK57kQAAAAAUnisAt+HZZ59NkixcuDBXXnnldvc9/PDD8+EPfzhJ8nd/93f5zGc+kz/96U+56qqrMmjQoAwZMiSrVq1KY2NjkuSUU07JW9/61ornOPvsszN37txMmTIl119/fW666ab0798/dXV1Scr3H7z88su7+mUCAAAAUHACwG1YtWpVkvI9+3Z0c8Xhw4dXfPzv//7v+fnPf54HHngg8+fPz4oVKzJ06NAcc8wxOeOMM3LyySdv9f6Af/d3f5ejjz4699xzT/74xz+mvr4+Bx98cE4//fScf/75LvUFAAAAYJcJALfh+uuv3+3ampqaXHjhhbnwwgt3ufbUU0/NqaeeutufGwAAAAA6cw9AAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMAEgAAAAABQYAJAAAAAACgwASAAAAAAFJgAEAAAAAAKTAAIAAAAAAUmAAQAAACAAhMAAgAAAECBCQABAAAAoMCqSqVSqaeboHtMnTo1DQ0NSZL+/fv3cDf0tJqamowbNy6LFy9Oc3NzT7cDheZ8g+7jfIPu4VyD7uN8o7POuc5ZZ52103XVe6oh9m5tA0Pv1dDQkHXr1vV0G9ArON+g+zjfoHs416D7ON/oCgLAXqRfv3493QJ7kc4hsCtCYc9yvkH3cb5B93CuQfdxvrE1u5rxWAIMvVTbkvBdvWwY2HXON+g+zjfoHs416D7ON7qCNwEBAAAAgAITAAIAAABAgQkAAQAAAKDABIAAAAAAUGACQAAAAAAosOqebgDoGRMnTkxzc3Nqamp6uhUoPOcbdB/nG3QP5xp0H+cbXaGqVCqVeroJAAAAAGDPsAQYAAAAAApMAAgAAAAABSYABAAAAIACEwACAAAAQIEJAAFgG77yla/koosuyi233NJjPdxyyy256KKLctVVV/VYD9CT9obzEOgZ69evzy233JJbbrklGzZs6Ol2APZp1T3dAACwbUOHDs0BBxyQ0aNH93QrANCt6uvr8/3vfz9Jcu6552bAgAE93BHAvksACAB7sQsuuCAXXHBBT7cBAADswywBBgAAAIACcwUg7INmz56du+++O3Pnzs3KlSszcODAjBo1KieddFLe8IY3ZPjw4VvUtLa25p577sm9996bhQsXZtCgQZk8eXIuueSSzJs3L1/96ldzxhln5EMf+tAWdffee2/uv//+zP//27vzqKrKxY3jz2GQSRSQFIdEMtLEVBxSy59Gabd7HcoptSyHi6llejOHlVimqWkWxL0OWWpminrL0Cz1ql3TnE0RUTFHxAlBARFkUA6/P1hnX08czBk4fT9rtdZhv3t437Pc7b2f8+73TUzUtWvXVLVqVT3xxBPq2LGjPDw87lOrgZJ19uxZLVmyRHv37lVWVpZ8fX3VvHlzdevWTRUqVDDWCw0NVXJysiZNmiQ3NzctWbJE8fHxys/PV61atdSjRw8FBwcrKSlJUVFRVvsLCQlR9+7d5ejoaOwvKipKS5YsUXBwsMaPH18STQdKjZs5D8+fP68BAwZIkqKjo7Vjxw59//33SkhIkCQFBgaqS5cuCg4OLqlmAPfFmTNn9M033yg2NlYZGRny9vZWQECAnn/+edWvX99q3StXruj777/Xtm3blJSUJLPZrGrVqhn3e+7u7lbrW65N7dq106BBgxQdHa1NmzYpKSlJLi4uCgwMVM+ePVW3bt0i9Tp06JCio6MVHx+vy5cvy93dXbVq1VLbtm311FNPyWQySfrf9dSiT58+kqQvvvhCVapUudtfF3DPXb58Wd9++6127typ5ORkOTg4qHLlymratKm6du1qdT8p3dpz2MqVK/XFF19IkkaNGqVWrVpZ7Wv16tWaNWuWHB0d9dFHHykwMPDeNxilDgEgUMb8+9//1sKFCyVJjo6OqlSpkrKysnT06FEdPXpUK1eu1LRp0+Tn52dsk5eXp0mTJikmJkaS5OnpKScnJ23evFk7d+5Uy5YtbR4rKytLEydO1IEDByRJHh4e8vT0VGJiohISErRq1SqNHz9eAQEB97jVQMn67bfftHz5cuXk5Mjb21uenp46d+6cli9fri1btmjSpElW55wk7dy5Uz/++KPMZrO8vLyUmZmpgwcPavz48RowYIAWLlyorKwseXp6ytXVVefOnVNUVJRSU1P1+uuvl1BLgdLrds7DhQsXatmyZXJ2dpa3t7fS0tIUGxur2NhY9e3bV126dCmh1gD31o4dOzRt2jTl5eWpXLly8vLyUmpqqpKTk7Vjxw698sor6t69uyTp3LlzGjdunJKSkiRJvr6+MpvNOnHihE6cOKH169dr3LhxqlGjRpHjZGZmavTo0Tp69Kg8PT3l5eWlCxcuaM+ePdq3b5+mTZum2rVrG+v//PPP+vTTT2U2m+Xm5qYHHnhAly9fVlxcnOLi4nTgwAENGTJEkuTn5ycHBwejXlWrVpWDg4OcnHiERdmTmpqqUaNGKTk5WY6OjvLx8ZHZbNapU6d06tQpbdmyRVOnTlWlSpUk3fpzWIcOHbRt2zbt379fn3/+uRo1aqTy5ctLki5cuKCvvvpKktStWzfCvz8x/u8JlCEZGRlavHixJOmVV15R586djZuggwcPasqUKUpPT9eKFSs0cOBAY7sFCxYoJiZGFStW1IgRI9SwYUNJhb8MR0REaOPGjTaPFxkZqQMHDsjf319DhgxRnTp1JElpaWmaPXu2tm7dqg8++ECzZs2Si4vLvWw6UKJiYmJUs2ZNDRs2zLhpOnz4sKZMmaKUlBSFh4fro48+stpmxYoVatOmjQYMGKAKFSrowoULGjNmjJKSkjR79mxVqVJFY8eOVVBQkAoKChQdHa358+dr3bp1evXVV42bNgCFbuc8XLZsmbp27aqePXvKxcVF2dnZioqK0ooVK/TVV1/pkUceKdITCijrTp8+rY8//lh5eXnq3LmzevXqJVdXV129elULFy5UdHS0oqKi1Lp1a/n4+Gjy5MlKSkpSvXr1NGzYMFWtWlVSYY/bf/3rXzpw4IAmTJig6dOnq1y5clbH2rZtmzw8PBQWFqbmzZsb240dO1YXLlzQ8uXL9fbbb0uScnNz9dlnn8lsNqtPnz564YUXjB7vMTExmjJlitauXauQkBAFBQVp4sSJVj16p0yZYvMtF6AsiIqKUnJysurVq6fRo0cb/5YvXryo8PBwxcXFadGiRRo6dKikW38OM5lMGjp0qIYOHar09HTNnTtXw4YNkyTNmjVLV65cUUBAgHr06FEyXwBKBcYABMqQY8eOKT8/X4GBgerevbvVL6D16tXTs88+K6nw9SeL9PR0rVq1SpI0fPhwI/yTpOrVq2vs2LE2X+Pdv3+/tm/fLnd3d7333nvGRUeSvL29NXLkSFWrVk0XLlwoNkAE7IWbm5smTJhg9YvpI488YvTUO3TokA4dOmS1Td26dTV8+HDjdQ5fX18988wzRvlbb72loKAgSZLJZFLnzp3l4uKi/Px8HT9+/F43CShzbuc8bNq0qfr06WP8SOXm5qa///3vatiwoRG8A/Zm6dKlys3NVePGjdWvXz+5urpKkpydndW3b18FBgYqPz9f27dv14YNG3Ty5Em5ubkpLCzMCP8kqVq1aho7dqwqVqyopKQk/fTTTzaPN2LECCP8s2zXsWNHSYU9dy1OnjypK1euSCrsrXT9cBfBwcF64YUXVLlyZR09evTufRlAKREfHy9Jat26tVWQXalSJQ0cOFCVK1fWmTNnJN3+c5ifn5/69u0rSfrpp58UGxurjRs3ateuXXJyctJbb71FD9o/OQJAoAypV6+e5s2bp/fff99meVpamqTC8SIs9uzZo2vXrsnX19fmeEdeXl42XwHetGmTJKlBgwZ64IEHipQ7OjrqySeflCTFxcXdcluAsuSJJ56Qj49PkeVNmjQxXjm0vKJh0bp1a2McIwvLDZ+Hh4fq1atnVWYymVSxYkVJhWPEALB2O+dhu3btbO6rbdu2kgofssxm812uKVBy8vPztXPnTknSc889V6TcZDKpX79+6tevn2rVqqUtW7ZIkkJCQuTp6VlkfQ8PD+N+b8+ePUXKq1SpoiZNmhRZXrNmTUnW17PrxzdbsGCBcnNzrbbp1auX5syZo+eff/4P2wmUNZbza9WqVUbQZ1GzZk3NmTNHU6dOlXRnz2F//etfjQ4f06dP15w5cyRJL730kmrVqnX3GoQyifgXKENcXFzk4uKi3NxcxcbG6sSJE0pJSVFKSorOnDmjU6dOFdnm5MmTkqSHH3642P3auhgcO3ZMUuFFZfDgwTa3y8rKkiSlpKTcalOAMqW4GyaTyaSaNWsqKSlJFy5csCq7vheFhaW3gyXoK871IT6AQrdzHhZ37bOMmZSdna3MzMwiA68DZdW5c+eUnZ0tSXr00UdtrlO/fn3j1fdPPvlEkmxO1mHx4IMPSpIxFt/1KleubHMby6vCeXl5xjI/Pz+1b99eP/74o1auXKl169YpKChIjz76qOrXr686depY9QoE7Env3r01YcIEJSYm6vXXX1dAQICCgoJUr149PfbYY1bXoTt5DjOZTHrzzTf15ptvGm+F1alTR507d74XzUIZQwAIlCEFBQVasWKFFi9ebNzcSYVhQmBgoHx9fY2JPiwsF4cbzdZra/y+zMxMY3vLPoqTk5Nz020AyqLfj3l0PctYfVevXr3pbX7fMxDAH7ud87C4YO/6GU2vXbt2F2oHlA6W+zcHBwebPfqKW98y8YAtlvvE359fkm75dcKBAweqadOmWrdunfbu3avdu3dr9+7dkgrP43bt2unll1++4fkOlEX169fX9OnT9cMPP2jHjh06fvy4jh8/rpUrV8rBwUENGzZU//795e/vf8fPYZUrV1bDhg21fft2SdIzzzxDuA5JBIBAmfLNN99o4cKFcnZ2Vu/evRUcHKzq1asbDzJRUVFFAkDLjdn1geHvXbp0qcgyy81ep06dFBoaereaAJRJlhsxW1JTUyXpph60ANy+2zkPr169esMfuWxtA5Rllod8s9ms3Nxcubm53XB9Z2dnXbt27YZDT1y8eFFS8YH6rWrSpImaNGmi/Px8JSQk6MCBA/r111+1b98+RUdHKysry5gJGLAnlStXVv/+/dW/f39dvHhR8fHx2rt3r7Zu3aqYmBiFhYVp9uzZd/wctnv3biP8k6RFixapZcuWf/gGCuwfYwACZciaNWskSX369NGLL76owMBAq14Mtm7eLL/o2nptw+LgwYNFllWvXl1S4UxuxTl27Jg2bNigw4cP31wDgDLK8irG7+Xn5ysxMVGS9NBDD93PKgF/OrdzHtoaGuP6fVWpUkXOzs53sZZAyfLz8zN6mZ8+fdrmOtHR0RozZoxWr15tjJ+ZkJBQ7D4t94l3ep2z3DeeOHFCUmFYWbt2bXXq1EkTJkwwJvSxjEsI2IusrCxt2LBBW7duNZZVqlRJrVq10pAhQzRjxgx5enoqIyNDcXFxd/QclpmZqenTp0sq7Pnn6+urS5cuadasWfegZShrCACBMiQ9PV3S/8K562VlZWnbtm1FllsmGjh+/LiOHDlSpDwxMVGxsbFFlj/++OOSpJiYGKtZhS2uXr2qjz/+WBEREcU+YAH2Ys+ePUYPiOvt2LFDqampcnFxsTkIOoC753bOQ1uzlprNZq1atUqSbE6OBZRlnp6exoyh//nPf4qUZ2dna8WKFdq/f78qVqyopk2bGuteP16fRXJysnGf+MQTT9xR3WJiYhQREaGFCxfaLLdMHMLEPLA3eXl5ioiI0EcffWTzzStvb2+jh63ZbL6j57AvvvhCFy9elK+vrwYMGGCMIbh161arGYPx50QACJQhlkGYv/vuO2VkZEgq7PkQExOjd955xwgIr7+BCwoKMgY7j4yMtLpIHDx4UB988IHNCQf+7//+T/7+/srPz9e0adOsfoE6f/68Jk+erDNnzujBBx9U69at73pbgdIkJydHkyZNsupNER8fr88//1yS9Pzzz1v1xgVw993Oebh+/XpFR0cbY5dlZmYqIiJCR44ckZOTk7p06XL/GgDcJz179pRU+O9/7dq1xn1eenq6pk2bptTUVPn6+qpZs2Zq3769ypcvr7S0NE2dOtUqZD99+rSmTJkis9msBg0aqEGDBndUr2bNmslkMunXX3/V8uXLre5XT506pblz50qSEUpK1mN//n6SH6Cs8Pb21sMPPyyz2azw8HAlJycbZVeuXNGiRYt05swZubq6qn79+rf9HLZ9+3Zt2LBBkvTaa6/J3d1dzZo1U5s2bSRJn3/+uTFkBv6cGAMQKENeeeUVTZw4UXFxcerbt698fHyUkZGhnJwcPfjggxo6dKg+/fRTHTx4UKGhoYqMjJSHh4dGjhypsWPHKjExUW+88YYeeOAB5eTk6PLly3Jzc1ObNm20ceNGq4kJnJycFBYWpnHjxunw4cMaNGiQfH19Jf3vBszPz09hYWG8PgW717ZtW/3yyy9644035O3trYKCAqWlpUmSGjVqpB49epRwDQH7dzvnYbNmzfTll18qKipKXl5eunjxoq5duyYHBwcNGzbMeP0RsCeNGzfWSy+9pKioKE2fPl3z5s2Tu7u7UlNTZTab5ebmphEjRsjZ2Vk+Pj4aNWqUPvzwQ+3atUv9+/eXr6+v8vPzjaCgRo0aGj58+B3Xy9/fXy+88IKio6M1b948ff3116pUqZKys7ONXlGWMdIsvLy85OPjo9TUVI0ZM0a+vr6aOHHiDSctAUqjwYMHKywsTDExMQoNDZWPj4+cnJyUmppqXJcGDx5s9AS81eewjIwMzZw5U5LUokULtWjRwjj2gAEDtHfvXl26dEkzZszQu+++ez+bjlKEABAoQ5o2barx48dr6dKlOnLkiC5fvqwaNWqodevWat++vZycnHTw4EFt3LhReXl5cnAo7ORbo0YNRUZG6ttvv9X27dt18eJFeXh4qEWLFurdu7c2bdokqehswH5+foqIiNCKFSu0efNmnT9/XuXKlVPt2rXVsmVLdejQgV5P+FOoW7euOnbsqEWLFik+Pl65ubkKCAjQ008/rQ4dOjCzGnAf3M55OHjwYAUHB2vNmjU6e/asXFxc1LhxY3Xv3t14TRKwRz179lRgYKCWL1+uo0ePKj09Xb6+vmrcuLG6dOliFX43atRIkZGRWrZsmWJiYoxX6gMDA9WyZUt17NjR5mQ6t6Nfv356+OGHtXbtWp04cUIpKSlydnaWv7+/mjVrpi5duhizekuSyWTS0KFDNWfOHCUlJSkzM9PqB2ugrAgMDFR4eLi+++477d+/3wjkvby89Oijj6pTp05W16VbfQ777LPPlJ6eLnd3dw0cONDq2BUqVNBrr72madOmadeuXVq/fr3atm1739qO0sNUUFBQUNKVAFCywsPD9fPPP+vVV19Vt27dSro6AADctvPnz2vAgAGSpK+++kre3t4lXCMAAICSRw9AwM6lpKRo1qxZMplMGj58uDw8PKzKc3JytHfvXkmFvSsAAAAAAIB9YRIQwM55eXnpyJEj2rVrl2bOnGlMHiIVzuw2depUpaen66GHHlJQUFAJ1hQAAAAAANwL9AAE7Jyzs7MGDhyoTz75RL/88ou2bNkiHx8fmc1mpaWlqaCgQJUqVdKIESMYUwUAAAAAADtEAAj8CbRq1Uo1a9bUDz/8oLi4OF24cEGOjo6qWbOmmjdvrk6dOhkzTgEAAAAAAPvCJCAAAAAAAACAHWMMQAAAAAAAAMCOEQACAAAAAAAAdowAEAAAAAAAALBjBIAAAAAAAACAHSMABAAAAAAAAOwYASAAAAAAAABgxwgAAQAAAAAAADtGAAgAAAAAAADYMQJAAAAAAAAAwI4RAAIAAAAAAAB2jAAQAAAAAAAAsGMEgAAAAAAAAIAdIwAEAADAHTOZTDKZTGrRokWJ1uOpp56SyWRSrVq1SrQeAAAApQkBIAAAAAAAAGDHCAABAAAAAAAAO+ZU0hUAAABA2VdQUFDSVQAAAEAx6AEIAAAAAAAA2DECQAAAAAAAAMCOEQACAADgjhU3C3BCQoJRNn/+fEnSrl271KdPH/n7+8vV1VVVqlTRs88+q2XLlv3hcX799Ve9+uqrxrY1a9ZU165dtWXLlpuua0FBgRYvXqwOHTqoevXqcnV1lb+/v7p166ZVq1bZ3CYqKspoh5ubm44dO2ZzvcOHD8vV1VUmk0murq46dOjQTdcLAADgXjEVMGALAAAA7pDJZJIkNW/eXNu3bzeWJyQkKCAgQJL05Zdf6uTJk5owYYLMZrPN/bzzzjuaPHmyzbKIiAiNHDlS+fn5No8fGRmpZcuWaePGjfL391dCQkKR9VJSUtS5c+cbBoZ/+ctfNH/+fPn5+Vkt79Chg3788UdJ0nPPPafVq1cX2fbpp5/Whg0bJEmTJ0/WO++8U+xxAAAA7hcCQAAAANyxmwkAGzVqpL1798rJyUndu3dX06ZNZTabtWrVKiM0M5lM2rp1a5GehN9++626d+9u/N2uXTs988wzcnR01H//+1+tXr1aJpNJFStWVHp6us0A8PLly2revLni4+MlScHBwerUqZO8vb2VmJio7777ztimYcOG+uWXX+Tp6Wlsf+rUKQUFBeny5cuSpG+++UbdunUzyhcsWKA+ffoYbd21a5ecnJhzDwAAlDwCQAAAANyxmwkAJalKlSpas2aNGjVqZLV9nz59tGDBAknSoEGDNGvWLKMsKytLgYGBOnfunJycnLRo0SK9+OKLVtsvXbpUvXv31rVr1yTJZgAYGhqquXPnSpKmTp2qkSNHGvWWpNzcXIWGhmrhwoWSpFGjRmnq1KlW+5g5c6beeOMNSVL16tUVHx8vT09Ppaamqm7dukpJSZGTk5N27typ4ODgm/vyAAAA7jHGAAQAAMB9s3Tp0iLhnySNGTPG+BwTE2NVNn/+fJ07d06SFBYWViT8k6QePXpoxIgRxR73xIkT+vLLLyUVho2jRo2yCv8kycXFRXPnzlWtWrUkFYZ9eXl5VusMHjxYrVq1kiSdOXNG48aNk1QYFqakpBifCf8AAEBpQgAIAACA++Lxxx9XmzZtbJbVqVNH5cuXlySdP3/eqmzx4sWSCgO6f/zjH8Xuf9iwYXJ0dLRZNn/+fGPcweHDhxe7j3Llyqlv376SpMzMTKvejFJhT8c5c+bIxcVFkvTPf/5TM2bM0Lx58yRJdevW1XvvvVfs/gEAAEoCASAAAADui8aNG9+w3MfHR5KUk5NjLMvLy9OuXbskFQaIXl5exW7v5+enRx55xGbZpk2bJEmOjo567LHHbliPpk2bGp/37dtXpLxOnTpGyJefn68hQ4aooKBADg4OVuEgAABAaUEACAAAgPvC29v7huWWV3KvH6L6+PHjxmu4derU+cNj1K5d2+by3377TVJhYOfg4CCTyVTsfx06dDC2S05Otrm/UaNGqWHDhlbLhgwZoieffPIP6wgAAHC/EQACAADgvihXrtwtb5Oenm58rlix4h+ub3mN+PdSU1Nv+diSdOXKFZvLnZyc1L59e6tlnTt3vq1jAAAA3GtOJV0BAAAAoDjXT9RhmeH3RrKzs2+4Hy8vL3344Yc3ffwGDRrYXH7kyBGFh4dbLRs6dKh2794tZ2fnm94/AADA/UAACAAAgFLLMi6gVDjr7h+xzBZsaz9nz56V2WzWoEGD7qhOBQUFCg0NNcYqrFy5spKTkxUXF6cPP/yQSUAAAECpwyvAAAAAKLUCAgLk7u4uScZkIMXJycnR/v37bZYFBQVJkjIyMv4wSExISNCSJUu0ZMkSnT17tkj57NmzjUlFWrVqpXXr1snJqfB39UmTJungwYM3bhQAAMB9RgAIAACAUsvJyUmtWrWSJJ08eVJbt24tdt3o6Ohix+wLCQkxPi9fvvyGx3z33XfVq1cv9erVy2pGYqmwF+Lo0aONus2cOVMNGjTQ8OHDJRXOWhwaGiqz2fyHbQMAALhfCAABAABQqg0YMMD4PHr0aJtjAaalpSksLKzYffTr18+YhGTKlCnFTgqyfv16LVq0SJLUrl07PfTQQ1blr7/+ujIyMiQVjvn32GOPSZLGjRunWrVqSZK2bdumGTNm3GTrAAAA7j0CQAAAAJRqXbt2VevWrSVJmzdvVvv27RUbG2uU79ixQyEhITpx4oQqVKhgcx9+fn569913JUmnT59WSEiIfv75Z6OnXmpqqsLDw9WpUycVFBTI2dlZH3/8sdU+li5dqu+//16SVK1aNb3//vtGmbu7u6ZPn278PWbMGCUmJt554wEAAO4CAkAAAACUaiaTSYsWLVJAQIAkae3atWrUqJHc3d1Vvnx5tWjRQrGxsWrXrp1efvnlYvczZswY9e7dW5K0b98+hYSEyM3NTT4+PvL19dXbb7+t7OxsOTs7a968eVYzAKempmro0KHG3+Hh4fL09LTaf/v27dWtWzdJUmZmpgYOHHjXvgMAAIA7QQAIAACAUq9GjRravHmz/va3vxnLsrOzlZWVJUdHR7322mtasWKFHByKv711cHDQggULFBkZKW9vb0mFY/alpaWpoKBAktSsWTNt2rTJCAot3nrrLSUnJ0uSnn76afXo0cPmMSIjI41eiGvWrNHXX399+40GAAC4S0wFlrsdAAAAoAw4cOCANm3apEuXLql69epq27atqlatekv7yM3N1U8//aTDhw/r2rVrqlGjhho0aKB69erdo1oDAACUHAJAAAAAAAAAwI7xCjAAAAAAAABgxwgAAQAAAAAAADtGAAgAAAAAAADYMQJAAAAAAAAAwI4RAAIAAAAAAAB2jAAQAAAAAAAAsGMEgAAAAAAAAIAdIwAEAAAAAAAA7BgBIAAAAAAAAGDHCAABAAAAAAAAO0YACAAAAAAAANgxAkAAAAAAAADAjhEAAgAAAAAAAHaMABAAAAAAAACwYwSAAAAAAAAAgB0jAAQAAAAAAADsGAEgAAAAAAAAYMcIAAEAAAAAAAA7RgAIAAAAAAAA2DECQAAAAAAAAMCOEQACAAAAAAAAdowAEAAAAAAAALBjBIAAAAAAAACAHSMABAAAAAAAAOwYASAAAAAAAABgxwgAAQAAAAAAADtGAAgAAAAAAADYMQJAAAAAAAAAwI4RAAIAAAAAAAB2jAAQAAAAAAAAsGP/D21Sr8+P5M2zAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 480,
       "width": 640
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure Size: (640 x 480)>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot\n",
    "plot = (ggplot(ols_tidy, aes(y='coef', x='index'))\n",
    "        + geom_point(aes(y='coef'), size=3, fill=\"red\", color=\"\")\n",
    "        + geom_errorbar(aes(ymin=\"lower\", ymax=\"upper\"), width=0.01, size=2, alpha=.3)\n",
    "        + geom_hline(aes(yintercept=0), color=\"red\", linetype=\"dotted\") \n",
    "        + theme_light()\n",
    "       )\n",
    "plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb83a4a",
   "metadata": {},
   "source": [
    "#### See more in the [documentation of statsmodels](https://www.statsmodels.org/stable/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada3d008",
   "metadata": {},
   "source": [
    "## Pratice\n",
    "\n",
    "Time for you to practice. \n",
    "\n",
    "- Estimate a different OLS model using the stats.models api. Add any variable you want to examine the effects or any interaction between the variables already there. \n",
    "- Build a scatter plot with: \n",
    "    - Predicted outcomes for all observations based on your model (y-axis)\n",
    "    - Observed values (x-axis)\n",
    "    - Line with the perfect fit between y and x\n",
    "    \n",
    "Tips:\n",
    "\n",
    "- You can get the fitted values with `model.fittedvalues`\n",
    "- the perfect fit comes with a 45 degree line `geom_abline(intercept = 0, slope = 1, size = 0.5)`\n",
    "\n",
    "\n",
    "Read more here for other diagnostics: https://www.statsmodels.org/stable/examples/notebooks/generated/ols.html    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7f450493",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add your response here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917272c3",
   "metadata": {},
   "source": [
    "## Statistical learning with sklearn\n",
    "\n",
    "As we discussed in the lecture, in the machine learning tradition, we are interest in predictive modeling, instead of understanding relationship. These are the key features on machine learning models:\n",
    "\n",
    "- The goal i is to **_predict_** values of the outcome, $\\hat{y}$\n",
    "  \n",
    "- Models are treated as a **_black box_**\n",
    "\n",
    "- the model doesn't need to be interpretable as long as it provides an accurate prediction of $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5060b1",
   "metadata": {},
   "source": [
    "## Machine Learning Workflow\n",
    "\n",
    "The figure below from Jorge Cimentada's book _Machine Learning for Social Science_ provides a nice summary of the traditional machine learning workiflow. \n",
    "\n",
    "![](https://cimentadaj.github.io/ml_socsci/img/socsci_wflow3_smaller.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f8ee9b",
   "metadata": {},
   "source": [
    "In words: \n",
    "    \n",
    "- Start with a dataset\n",
    "- Split between training and test\n",
    "- Do some pre-processing\n",
    "- Train the model (with or without cross-validation)\n",
    "- Select best parameters (fine-tuning the model)\n",
    "- Evaluate the model in the **test set.**\n",
    "\n",
    "All these steps will be performed using the `sklearn` library. The documentation for `sklearn` is super rich. So I strongly encourage you to check their website and their tutorials: https://scikit-learn.org/stable/tutorial/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3c5b71",
   "metadata": {},
   "source": [
    "### Simple Example: OLS just to learn the mechanics of the sklearn API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead4472a",
   "metadata": {},
   "source": [
    "#### Open the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bdf3822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "# load the dataset as a pandas dataframe\n",
    "diabetes = datasets.load_diabetes(as_frame=True)[\"frame\"]\n",
    "\n",
    "# features\n",
    "X = diabetes.drop(columns=\"target\")\n",
    "\n",
    "# target\n",
    "y = diabetes[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546c5dbb",
   "metadata": {},
   "source": [
    "#### Split between training and test\n",
    "\n",
    "- `train_test_split` method: \n",
    "\n",
    "    - returns: train and test for X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "55539526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state = 417)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9accc772",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5125ca2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age    0\n",
       "sex    0\n",
       "bmi    0\n",
       "bp     0\n",
       "s1     0\n",
       "s2     0\n",
       "s3     0\n",
       "s4     0\n",
       "s5     0\n",
       "s6     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any missing? \n",
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f5d75581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.511817e-19</td>\n",
       "      <td>1.230790e-17</td>\n",
       "      <td>-2.245564e-16</td>\n",
       "      <td>-4.797570e-17</td>\n",
       "      <td>-1.381499e-17</td>\n",
       "      <td>3.918434e-17</td>\n",
       "      <td>-5.777179e-18</td>\n",
       "      <td>-9.042540e-18</td>\n",
       "      <td>9.293722e-17</td>\n",
       "      <td>1.130318e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age           sex           bmi            bp            s1  \\\n",
       "mean -2.511817e-19  1.230790e-17 -2.245564e-16 -4.797570e-17 -1.381499e-17   \n",
       "std   4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02   \n",
       "\n",
       "                s2            s3            s4            s5            s6  \n",
       "mean  3.918434e-17 -5.777179e-18 -9.042540e-18  9.293722e-17  1.130318e-17  \n",
       "std   4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stardandization?\n",
    "X.describe().loc[[\"mean\", \"std\"],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "619c8505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age    float64\n",
       "sex    float64\n",
       "bmi    float64\n",
       "bp     float64\n",
       "s1     float64\n",
       "s2     float64\n",
       "s3     float64\n",
       "s4     float64\n",
       "s5     float64\n",
       "s6     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any categorical?\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ef9e9d",
   "metadata": {},
   "source": [
    "This dataset is pretty much clean for us, we can skip pre-processing steps. \n",
    "\n",
    "If you want see more about pre-processing steps with `skelearn`, check here: https://scikit-learn.org/stable/modules/preprocessing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe3ec82",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "**IMPORTANT**: The modeling API follows the same framework (despite the model). You can fit many different models with very similar code. Let's start with a simple OLS. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a2cb4257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import model \n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Instantiate the modeling object\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437b205a",
   "metadata": {},
   "source": [
    "#### Evaluate the model - use the test set!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cd0d751e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4799898648936971"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit statistic (metric for how wrong we are) -- R^2\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "38b5dc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115.49491094 210.09290977 189.5242481  175.43515176 201.46238906\n",
      "  81.15639425 152.8271523  253.37232049 104.76783223 229.40236393\n",
      "  88.53943327 137.94591634 111.7907669   75.00586818 102.69608919\n",
      "  88.82851727 144.16536153 166.08420474 190.44728589  95.72804239\n",
      " 236.09610547 142.32618368 208.17277143  81.42304444 136.95821211\n",
      " 114.61153969 110.98084478 157.09470122 161.16279034 148.62899149\n",
      " 121.12546219 232.37582345 166.18001126 183.23857245 228.6220361\n",
      " 120.43129965  76.13668714  85.79445075 213.28227144 258.72884379\n",
      " 174.40941255 118.59833036 181.34022491 163.09109404 184.74115281\n",
      " 206.51010643 124.40167753 132.45563373  86.41756416 154.62456976\n",
      " 115.99654319 174.18705985 125.04652635 138.79780373 145.15929403\n",
      "  62.46630334 153.85176433 200.92345233 210.50146136 134.74179524\n",
      " 253.20969321  95.26282909  56.77716228 260.1568294  187.06904303\n",
      " 249.2484531  275.68356911]\n"
     ]
    }
   ],
   "source": [
    "## if you want to calculate the mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# predicted values\n",
    "yhat = model.predict(X_test)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fbf04418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3325.658847637309"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## estimate out of sample predictions\n",
    "mean_squared_error(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f288f0d7",
   "metadata": {},
   "source": [
    "### Many, many models, and an API to rule them all!\n",
    "\n",
    "Our performance with the simple linear regression was not great. Let's see if we get better using more complex models. We will try three different families of models. Again, you will learn about these models in DS II\n",
    "\n",
    "- **Elastic-net:** linear model with regularization parameters. \n",
    "- **Support Vector Machine**: a supervised model that allows more non-linearity between the parameters\n",
    "- **Decision Tree:** A model that uses a set of boolean rules in a non-parametric fashion that splits your data in multiple groups for supervised tasks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "52a6f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for models\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# setup for metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# setup for dataset\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "212b15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset as a pandas dataframe\n",
    "diabetes = datasets.load_diabetes(as_frame=True)[\"frame\"]\n",
    "\n",
    "# features\n",
    "X = diabetes.drop(columns=\"target\")\n",
    "\n",
    "# target\n",
    "y = diabetes[\"target\"]\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state = 417)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb242a0d",
   "metadata": {},
   "source": [
    "### Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "727167d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model\n",
    "\n",
    "# Instantiate the modeling object\n",
    "model_ols = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model_ols.fit(X_train,y_train)\n",
    "\n",
    "# Predict and calculate MSE in the test\n",
    "y_pred_ols = model_ols.predict(X_test)\n",
    "mse_ols = mean_squared_error(y_test, y_pred_ols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a6fadf",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "380df35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Elastic Net model\n",
    "# alpha and l1_ratio are hyper parameter (learning is here!)\n",
    "elastic_net = ElasticNet(alpha=0.01, l1_ratio=1)  \n",
    "elastic_net.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate MSE in the test\n",
    "y_pred_en = elastic_net.predict(X_test)\n",
    "mse_en = mean_squared_error(y_test, y_pred_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2f5cb8",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "942e80ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the SVM model\n",
    "svm = SVR(kernel='linear')  # Using linear kernel for demonstration\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate MSE in the test\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "mse_svm = mean_squared_error(y_test, y_pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cca6f43",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d4cccc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Decision Tree model\n",
    "tree = DecisionTreeRegressor(random_state=0,  max_depth=50)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate MSE in the test\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "mse_tree = mean_squared_error(y_test, y_pred_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802f5561",
   "metadata": {},
   "source": [
    "## Out-of-sample predictions\n",
    "\n",
    "This is really important: **we always evaluate the models using out of sample, unseen data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c1000cb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "      <th>models</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3324.324519</td>\n",
       "      <td>elastic-net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3325.658848</td>\n",
       "      <td>ols</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7071.125649</td>\n",
       "      <td>svm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8250.611940</td>\n",
       "      <td>tree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        values       models\n",
       "1  3324.324519  elastic-net\n",
       "0  3325.658848          ols\n",
       "2  7071.125649          svm\n",
       "3  8250.611940         tree"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"values\":[mse_ols, mse_en,mse_svm, mse_tree], \n",
    "               \"models\":[\"ols\", \"elastic-net\", \"svm\", \"tree\"]}).sort_values(\"values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb34951",
   "metadata": {},
   "source": [
    "### Let's see the fit in the training data (JUST FOR FUN --- this is not really anything we care about!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2f5c10a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model\n",
    "\n",
    "# Instantiate the modeling object\n",
    "model_ols = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model_ols.fit(X_train,y_train)\n",
    "\n",
    "# predic and calculate MSE\n",
    "#y_pred_ols = model_ols.predict(X_test)\n",
    "y_pred_ols = model_ols.predict(X_train)\n",
    "mse_ols = mean_squared_error(y_train, y_pred_ols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "32450ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Elastic Net model\n",
    "# alpha is a hyper parameter (learning is here!)\n",
    "elastic_net = ElasticNet(alpha=0.01, l1_ratio=1)  \n",
    "elastic_net.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate MSE\n",
    "y_pred_en = elastic_net.predict(X_train)\n",
    "mse_en = mean_squared_error(y_train, y_pred_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8e99ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the SVM model\n",
    "svm = SVR(kernel='linear')  # Using linear kernel for demonstration\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate MSE\n",
    "y_pred_svm = svm.predict(X_train)\n",
    "mse_svm = mean_squared_error(y_train, y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f80b0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Decision Tree model\n",
    "tree = DecisionTreeRegressor(random_state=0,  max_depth=20)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate MSE\n",
    "y_pred_tree = tree.predict(X_train)\n",
    "mse_tree = mean_squared_error(y_train, y_pred_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "568fc5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "      <th>models</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006667</td>\n",
       "      <td>tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2793.124358</td>\n",
       "      <td>ols</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2802.447120</td>\n",
       "      <td>elastic-net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5765.841372</td>\n",
       "      <td>svm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        values       models\n",
       "3     0.006667         tree\n",
       "0  2793.124358          ols\n",
       "1  2802.447120  elastic-net\n",
       "2  5765.841372          svm"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"values\":[mse_ols, mse_en,mse_svm, mse_tree], \n",
    "               \"models\":[\"ols\", \"elastic-net\", \"svm\", \"tree\"]}).sort_values(\"values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37c6686",
   "metadata": {},
   "source": [
    "## Quizz: Discuss with your colleague.\n",
    "\n",
    "- Why do tree-based models do so much better in the training data compared to the test data?\n",
    "\n",
    "   - Take five minutes to read a bit about what tree-based models are, and discuss with your colleagues. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987d7c57",
   "metadata": {},
   "source": [
    "### Hyper-Parameter Tunning and Cross Validation\n",
    "\n",
    "As you saw above, more advanced machine learning models have hyper-parameters. \n",
    "\n",
    "Hyperparameters are parameters that are not learned directly from the data but are set in advance before the training process begins, bur their best-values can be learned with training. Examples include the learning rate in gradient descent in deep-learning, the depth of a decision tree, or the number of neighbors in a k-nearest neighbors algorithm.\n",
    "\n",
    "The way we choose the values for hyper-parameters is by looking at the performance of the models. \n",
    "\n",
    "### Cross-validation\n",
    "\n",
    "If we were to find the best-values for hyperparameters looking always to the test-set, we would be pretty much training the model on the test set. Remember, we should always avoid this. The test set should be unseen data, and we should keep its integrity. This process is commonly described as [data leakage](https://towardsdatascience.com/what-is-data-leakage-and-how-can-it-be-avoided-in-machine-learning-eb435a27c3e3)\n",
    "\n",
    "For this reason, when training machine learning models, we often rely on resampling methods, such as cross-validation. These methods allow us to fine tune our models by taking multiple samples of the training data, and training the model multiple times. \n",
    "\n",
    "Read here a nice and shor introduction to cross-validation: https://neptune.ai/blog/cross-validation-in-machine-learning-how-to-do-it-right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6264fdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Obs. to train on = 300, N obs to test on = 75\n",
      "N Obs. to train on = 300, N obs to test on = 75\n",
      "N Obs. to train on = 300, N obs to test on = 75\n",
      "N Obs. to train on = 300, N obs to test on = 75\n",
      "N Obs. to train on = 300, N obs to test on = 75\n",
      "Total numbers of models run = 5\n"
     ]
    }
   ],
   "source": [
    "# lets see the mechanics first\n",
    "from sklearn.model_selection import train_test_split # Train-test split\n",
    "from sklearn.model_selection import LeaveOneOut # Leave One Out Cross Validation\n",
    "from sklearn.model_selection import KFold # K-fold Cross validation\n",
    "\n",
    "# Intialize the K-Folds (splits)\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Split the data\n",
    "k_splits = kf.split(X_train)\n",
    "\n",
    "# Let's look at the splits\n",
    "n_models =0\n",
    "for train, test in k_splits:\n",
    "    print(f\"N Obs. to train on = {train.shape[0]}, N obs to test on = {test.shape[0]}\") #\n",
    "    n_models += 1 # Count the number of models\n",
    "\n",
    "print(f\"Total numbers of models run = {n_models}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a1e896ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Fold 2:\n",
      "Fold 3:\n",
      "Fold 4:\n",
      "Fold 5:\n"
     ]
    }
   ],
   "source": [
    "# what the splits are? Index of the data\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Split the training data\n",
    "k_splits = kf.split(X_train)\n",
    "\n",
    "# containers to store the data\n",
    "train_data = list()\n",
    "val_data = list()\n",
    "\n",
    "# iterate\n",
    "for fold_number, (train_indices, val_indices) in enumerate(k_splits):\n",
    "    print(f\"Fold {fold_number + 1}:\")\n",
    "    \n",
    "    # Split your data into training and validation sets using the indices\n",
    "    train_data.append([X_train.iloc[i] for i in train_indices])\n",
    "    val_data.append([X_train.iloc[i] for i in val_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a7abf7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.023677</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.065486</td>\n",
       "      <td>-0.081413</td>\n",
       "      <td>-0.038720</td>\n",
       "      <td>-0.053610</td>\n",
       "      <td>0.059685</td>\n",
       "      <td>-0.076395</td>\n",
       "      <td>-0.037129</td>\n",
       "      <td>-0.042499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.016281</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.046085</td>\n",
       "      <td>0.011544</td>\n",
       "      <td>-0.033216</td>\n",
       "      <td>-0.016032</td>\n",
       "      <td>-0.010266</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.043984</td>\n",
       "      <td>-0.042499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.059871</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.076786</td>\n",
       "      <td>0.025315</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.016849</td>\n",
       "      <td>-0.054446</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.029935</td>\n",
       "      <td>0.044485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.027178</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.006728</td>\n",
       "      <td>0.035644</td>\n",
       "      <td>0.079612</td>\n",
       "      <td>0.070710</td>\n",
       "      <td>0.015505</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.040673</td>\n",
       "      <td>0.011349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0.009016</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.039618</td>\n",
       "      <td>0.028758</td>\n",
       "      <td>0.038334</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>-0.072854</td>\n",
       "      <td>0.108111</td>\n",
       "      <td>0.015568</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>-0.081798</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>-0.019442</td>\n",
       "      <td>0.039710</td>\n",
       "      <td>0.057558</td>\n",
       "      <td>-0.069172</td>\n",
       "      <td>0.108111</td>\n",
       "      <td>0.047190</td>\n",
       "      <td>-0.038357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>-0.052738</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.062252</td>\n",
       "      <td>0.011544</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.036700</td>\n",
       "      <td>0.122273</td>\n",
       "      <td>-0.076395</td>\n",
       "      <td>-0.086827</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.001751</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.070875</td>\n",
       "      <td>-0.022885</td>\n",
       "      <td>-0.001569</td>\n",
       "      <td>-0.001001</td>\n",
       "      <td>0.026550</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.022517</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.009016</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.012673</td>\n",
       "      <td>0.028758</td>\n",
       "      <td>-0.018080</td>\n",
       "      <td>-0.005072</td>\n",
       "      <td>-0.047082</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.023371</td>\n",
       "      <td>-0.005220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>-0.027310</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.029770</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>-0.000688</td>\n",
       "      <td>0.041277</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.023647</td>\n",
       "      <td>0.011349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "31  -0.023677 -0.044642 -0.065486 -0.081413 -0.038720 -0.053610  0.059685   \n",
       "243  0.016281  0.050680 -0.046085  0.011544 -0.033216 -0.016032 -0.010266   \n",
       "290  0.059871  0.050680  0.076786  0.025315  0.001183  0.016849 -0.054446   \n",
       "236  0.027178 -0.044642  0.006728  0.035644  0.079612  0.070710  0.015505   \n",
       "423  0.009016  0.050680 -0.039618  0.028758  0.038334  0.073529 -0.072854   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "186 -0.081798  0.050680  0.042296 -0.019442  0.039710  0.057558 -0.069172   \n",
       "266 -0.052738  0.050680 -0.062252  0.011544 -0.008449 -0.036700  0.122273   \n",
       "213  0.001751 -0.044642 -0.070875 -0.022885 -0.001569 -0.001001  0.026550   \n",
       "190  0.009016 -0.044642 -0.012673  0.028758 -0.018080 -0.005072 -0.047082   \n",
       "229 -0.027310  0.050680 -0.015906 -0.029770  0.003935 -0.000688  0.041277   \n",
       "\n",
       "           s4        s5        s6  \n",
       "31  -0.076395 -0.037129 -0.042499  \n",
       "243 -0.002592 -0.043984 -0.042499  \n",
       "290  0.034309  0.029935  0.044485  \n",
       "236  0.034309  0.040673  0.011349  \n",
       "423  0.108111  0.015568 -0.046641  \n",
       "..        ...       ...       ...  \n",
       "186  0.108111  0.047190 -0.038357  \n",
       "266 -0.076395 -0.086827  0.003064  \n",
       "213 -0.039493 -0.022517  0.007207  \n",
       "190  0.034309  0.023371 -0.005220  \n",
       "229 -0.039493 -0.023647  0.011349  \n",
       "\n",
       "[300 rows x 10 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see data\n",
    "pd.DataFrame(train_data[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097aa294",
   "metadata": {},
   "source": [
    "we could iterate over these with a loop...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426e3816",
   "metadata": {},
   "source": [
    "### Easy implementation with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74217f4",
   "metadata": {},
   "source": [
    "Let's implement using `sklearn`. We actually don't need a loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5fc14670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# create my splits\n",
    "# what the splits are? Index of the data\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Split the data\n",
    "k_splits = kf.split(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6cdad8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.279e+05, tolerance: 1.706e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.498e+05, tolerance: 1.758e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.511e+05, tolerance: 1.755e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.584e+05, tolerance: 1.559e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.670e+05, tolerance: 1.794e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.477e+05, tolerance: 1.706e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.729e+05, tolerance: 1.758e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.719e+05, tolerance: 1.755e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.749e+05, tolerance: 1.559e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.906e+05, tolerance: 1.794e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.503e+05, tolerance: 1.706e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.760e+05, tolerance: 1.758e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.746e+05, tolerance: 1.755e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.771e+05, tolerance: 1.559e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.937e+05, tolerance: 1.794e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.517e+05, tolerance: 1.706e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.775e+05, tolerance: 1.758e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.760e+05, tolerance: 1.755e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.782e+05, tolerance: 1.559e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.953e+05, tolerance: 1.794e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.525e+05, tolerance: 1.706e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.785e+05, tolerance: 1.758e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.769e+05, tolerance: 1.755e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.788e+05, tolerance: 1.559e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Elastic Net parameters: {'alpha': 0.1, 'l1_ratio': 1}\n",
      "Best Score: 0.4555152864444504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tb186/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.963e+05, tolerance: 1.794e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "params = {\n",
    "    'alpha': [0.1, 0.5, 1, 2, 5],\n",
    "    'l1_ratio': [0, 0.25, 0.5, 0.75, 1]\n",
    "}\n",
    "\n",
    "# elastic net\n",
    "elastic_net = ElasticNet(max_iter=10000, tol=1e-5, random_state=42)\n",
    "\n",
    "# Grid search with 5-fold cross-validation\n",
    "grid_en = GridSearchCV(elastic_net, params, cv=kf, scoring='r2')\n",
    "grid_en.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and corresponding MSE\n",
    "print(\"Best Elastic Net parameters:\", grid_en.best_params_)\n",
    "print(\"Best Score:\", grid_en.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6f8c1ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree parameters: {'max_depth': 2, 'min_samples_split': 2}\n",
      "Best Score: 0.35160918571106714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "params = {\n",
    "    'max_depth': [None, 2, 4, 6, 8, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "grid_tree = GridSearchCV(tree, params, cv=kf, scoring='r2')\n",
    "grid_tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Decision Tree parameters:\", grid_tree.best_params_)\n",
    "print(\"Best Score:\", grid_tree.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "aa2f0740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN parameters: {'n_neighbors': 9}\n",
      "Best Score: 0.37833624073149236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "params = {\n",
    "    'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "}\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "grid_knn = GridSearchCV(knn, params, cv=kf, scoring='r2')\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best KNN parameters:\", grid_knn.best_params_)\n",
    "print(\"Best Score:\", grid_knn.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "383cf838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model based on cross-validation results\n",
    "best_model = min([grid_en, grid_tree, grid_knn], key=lambda x: -x.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9bc866fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNet(alpha=0.1, l1_ratio=1, max_iter=10000, random_state=42, tol=1e-05)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet(alpha=0.1, l1_ratio=1, max_iter=10000, random_state=42, tol=1e-05)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ElasticNet(alpha=0.1, l1_ratio=1, max_iter=10000, random_state=42, tol=1e-05)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which model?\n",
    "best_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b7d98c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1, 'l1_ratio': 1}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what else\n",
    "best_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4119d636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4555152864444504"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# error\n",
    "best_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "aa0a9f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set r2 for the best model: 0.4718501302973718\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the test set MSE\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "print(\"Test set r2 for the best model:\", r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf53b421",
   "metadata": {},
   "source": [
    "All of this only touches the tip of the iceberg on Machine Learning. If you want to go ahead and learn more before DS II, I would suggest you to: \n",
    "\n",
    "- Read [Introduction to Statistical Learning in Python](https://www.statlearning.com/)\n",
    "\n",
    "- Work through the [tutorials on sklearn webpage](https://scikit-learn.org/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3dccbeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook _week-9-models.ipynb to html\n",
      "[NbConvertApp] Writing 449036 bytes to _week-9-models.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert _week-9-models.ipynb --to html --template classic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
